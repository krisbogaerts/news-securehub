<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Reddit - NetSec</title><link>https://news.securehub.cc</link><description></description><item><title>Sliver C2 vulnerability enables attack on C2 operators through insecure Wireguard network</title><link>https://hngnh.com/posts/Sliver-CVE-2025-27093/</link><author>/u/catmandx</author><category>netsec</category><pubDate>Fri, 21 Nov 2025 13:19:57 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Sliver is a powerful command and control (C2) framework designed to provide advanced capabilities for covertly managing and controlling remote systems.Sliver supports Wireguard as a transport protocol with a custom Wireguard netstack. It is popular due to the open-source nature as well as extensibility, ease-of-use, and compatibility with Cobalt Strike BOFs. In versions 1.5.43 and earlier, the netstack does not limit traffic between Wireguard clients. This allows clients to communicate with each other without restrictions, potentially enabling leaked or recovered keypairs to be used to  or allowing port forwardings to be accessible from other implants.These Sliver versions are affected: Sliver 1.5.43 and earlier.Operators that use Wireguard protocol transport and port forwarding to access implants.Notes: images use colored border to show you where the command is executed:When the C2 Operator use the Wireguard functionality in Sliver, they need to:Create a Wireguard listener (a peer).
      sliver > wg -l 10002 -p

  [*] Starting Wireguard listener
  [*] Successfully started job #1
Now Sliver is listening on UDP port 10002 for Wireguard connections.Create an implant with the  option.
      sliver > generate beacon --wg c2.server.com:10002 --debug --skip-symbols --name beacon-wg
This will embed a wireguard peer configuration inside the implant.Execute the implant on the victim‚Äôs machine:
      Victim powershell $ .\beacon-wg.exe

  Now the implant becomes a Wireguard peer. The beacon should pop up on the operator‚Äôs sliver console:
  
  We can see the Wireguard private IP assigned to it is 100.64.0.4.Create operator Wireguard config:
      sliver > wg-config -s ./data/wireguard/wg_confs/wg0.conf
The operator connect his own machine to the wireguard listener:
      bash # wg-quick up wg0
  bash # ip a
We can see the Wireguard private IP assigned to the operator is 100.64.0.2.To facilitate port forwarding, Sliver implement the wireguard network stack to forward any packets between peers, this essentially create a traditional hub-and-spoke VPN server. Traffic between wireguard peers are not filtered .On the Sliver server and on the victim machine, the wireguard connection is not exposed as a network interface, it lives entirely inside the process.Crucially, if the operator uses  or any equivalent commands, they are creating a network interface on their machine. If they have any services listening on 0.0.0.0 (SSH, RDP, SMB, HTTP, etc), those services can also be accessed on the 100.64.0.2 interface by other wireguard peers.We can verify this behavior by perform pings from both sides:On the operator machine, we can ping the beacon since the OS knows where to send ICMP packets:In contrast, the victim machine is not aware that there‚Äôs a VPN connection since it only lives inside the beacon process, thus the ping fails:If a defender or malicious client get ahold of the wireguard config used by the client, then they can connect to the Sliver wireguard listener, and connect to the operator‚Äôs wireguard interface. Getting the wireguard connection config from the beacon is outside the scope of this article, the wireguard config is embedded into the beacon at compile time, as well as existing in memory, you can dump the memory or use some static analysis tool to retrieve the sliver wireguard. listener address, private key of the beacon and public key of the sliver listener.First you have to obtain a valid wireguard config, there are several ways to do this, exercise left to the reader, then creating a network interface using it:The victim can connect to the operator‚Äôs machine:Assuming the operator is running an HTTP server on their machine, the victim can now connect to it, the same applies to any services listening on 0.0.0.0:If the operator has set up port forwarding to access services inside a victim‚Äôs internal network, something like 100.64.0.4:1080 ‚Äì> internal-ad-server.corp.local:445Then other victims/beacons can also connect to that port forward, though this require some serious guesswork:When the beacon is executed on the victim machine, it will notify the Sliver server that a beacon has connected. This will only happen if you let the beacon finish handshaking with the server. This process is as follows:Step 1: the beacon use the embedded wireguard peer config to establish connection with the server. This embedded config will be shared with every other beacon, so it will only be used to initiate the connection before switching to a new config.Step 2: the beacon connect to 100.64.0.1:1337 (default key exchange endpoint) and receive a new, unique wireguard peer config.Step 3: perform handshake and let the operator know the beacon is online.If you are able to extract the initial Wireguard peer configuration, you can use it as-is to connect to the Wireguard listener, but if you keep using it, other beacons with the same executable will not be able to connect back, so this will generate some suspicion on the operator‚Äôs side.If the operator use the default configuration, you can use netcat to connect to 100.64.0.1:1337 and get a new, unencrypted Wireguard config unique to you, this way you gain access to the network while not letting them know you are there, the Sliver console does not have a way to show how many Wireguard config has been created, or how many is currently connected.https://github.com/BishopFox/sliver/security/advisories/GHSA-q8j9-34qf-7vq7https://nvd.nist.gov/vuln/detail/CVE-2025-27093]]></content:encoded></item><item><title>Esbuild XSS Bug That Survived 5B Downloads and Bypassed HTML Sanitization</title><link>https://www.depthfirst.com/post/esbuilds-xss-bug-that-survived-5-billion-downloads-and-bypassed-html-sanitization</link><author>/u/va_start</author><category>netsec</category><pubDate>Fri, 21 Nov 2025 00:03:07 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Esbuild has been downloaded 5 billion times since this XSS bug was introduced in 2022. The bug hid in a function that promised to escape html called . But, apparently, the promise was more of a suggestion. To bypass the HTML escaping, I used the , literally a quote . A malicious folder with a quote in its name could be used to attack anyone using the dev server. The fix was one line. The exploit involved making an invisible script take over your entire screen.¬†The Initial Finding: Suspicious XSSThis adventure kicked off with our depthfirst system tapping me on the shoulder like an overeager intern with a suspiciously confident smile.>  XSS in esbuild dev server: github.com/evanw/esbuild (40k Github stars)html.WriteString(escapeForHTML( ... ))In esbuild? Using a function literally named? Unlikely. I had the same reaction you‚Äôd have if someone told you a toaster was capable of launching a space shuttle: charming, but wrong.Our system claimed there‚Äôs an XSS bug inside code designed to prevent XSS? In a major codebase built around generating safe HTML? If true, that‚Äôs like finding out the lifeguard can't swim.Still, if valid, this would be a significant finding. The esbuilt npm package alone has five billion downloads. And a restless ‚Äúbut what if?‚Äù rang in the back of my mind. So I sighed, cracked my knuckles, and set out to prove the machine wrong. Spoiler: the machine was  wrong.The Investigation: A Friendly Challenge Turns Into a Rabbit HoleThe depthfirst system had already labeled it ‚Äúlow severity,‚Äù which is our polite way of telling engineers, ‚Äúnot a fire, but this smells funny.‚ÄùBut I couldn‚Äôt let it go. Even when a machine says ‚Äúlow severity,‚Äù I still want to understand  it thinks something is off. It‚Äôs like hearing your dog growl at a blank wall. Maybe it‚Äôs nothing, but maybe it‚Äôs time to call a priest.So I followed the trail into esbuild‚Äôs code.Here‚Äôs the vulnerable code :}
	}
		}
		html.WriteString(escapeForHTML(part))
		}
	}
}At first, nothing seemed odd. The dev server is creating the  title from directory listings. It's escaping¬† HTML in the folder names. All the classics get neutralized: But one thing  get escaped. Quotes .I have confirmed our system's finding and suddenly everything clicked into place. I gave my laptop a pat on the head to reward the AI.HTML 101: The Difference Between Text and Attributes correctly protects you when you put user-controlled text  tags, like:But esbuild wasn‚Äôt putting the escaped text there. It was putting it  an HTML attribute, in an :If your sanitization doesn‚Äôt escape double quotes, you can break out of the attribute and add your own. You can slap on a new , an event handler, or an entire circus of JavaScript!The correct function to use was :	text = escapeForHTML(text)
}
Crafting the Exploit: Making an Invisible Screen-Sized MousetrapOnce I realized I could break out of the attribute, the rest was pure puzzle-solving joy.I needed a folder name that:Included a double quote to terminate the attributeAdded a malicious attribute to execute JavascriptWorked even though esbuild would automatically append  at the endEasily triggered (because asking a user to click a link isn't sexy).Here‚Äôs the command that created the malicious directory:style="position:absolute;top:0;left:0;width:100vw;height:100vh;"This creates an invisible full-screen div. This is important for the next part.onmouseover="alert('xss')"The moment your cursor moves over the div, which is now the whole screen, boom. Arbitrary JavaScript execution.This dummy attribute was the key to neutralizing esbuild‚Äôs auto-appended /". I needed a place to  the trailing characters so they don't cause a syntax error in the other attributes.Reload the dev server. Move your mouse. Instant satisfaction.The Fix: A One-Word Patch and a Thoughtful MaintainerAfter confirming the exploit was real, I sent the automatically generated fix upstream. The patch was immediately merged.The fix? Literally a swap:+ escapeForAttribute(...)One word. Billions of future downloads affected.I love bugs like this. They're subtle, and make you think deeply about the edge cases of the code.The maintainers thanked us for finding and fixing the bug, and was correct to point out this didn't have a security impact. Since this only affects the dev server, and the dev server assumes a trusted environment, it‚Äôs not a ‚Äúsecurity vulnerability‚Äù in the traditional sense. And that‚Äôs true. This wasn‚Äôt a CVE-worthy disaster. No one‚Äôs production servers were melting because of this.But it was still a . An elusive, fun, intellectually stimulating bug that was completely exploitable.And depthfirst‚Äôs system correctly found, categorized, and drafted a patch. All automatically.I just got to be the human who enjoyed the ride.This adventure felt like tugging on a loose thread in a sweater: you don‚Äôt expect much, but suddenly half the sleeve is in your hand. All I did was follow a quote mark out of an attribute, and it led to a bug that had been downloaded billions of times. The funny part is that nothing here was ‚Äúwrong‚Äù in isolation. The trick was noticing the context had changed.  was perfectly fine for text, just not for attributes.Depthfirst surfaced the loose thread; I pulled it because I can‚Äôt resist seeing where those threads lead. Together, we solved a tiny mystery tucked away in a project downloaded five billion times.]]></content:encoded></item><item><title>Unquoted Paths: The Decades-Old Windows Flaw Still Enabling Hidden Code Execution</title><link>https://spektion.com/articles/unquoted-path-flaw/</link><author>/u/runtimesec</author><category>netsec</category><pubDate>Thu, 20 Nov 2025 19:47:04 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>When Updates Backfire: RCE in Windows Update Health Tools</title><link>https://research.eye.security/rce-windows-update-health-tools/</link><author>/u/vaizor</author><category>netsec</category><pubDate>Thu, 20 Nov 2025 07:16:20 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[What if a Microsoft‚Äëtool meant to protect Windows machines, actually opened up remote code execution (RCE) by re-using abandoned Azure blobs?That‚Äôs exactly what we discovered in Microsoft‚Äôs Update Health Tools (KB4023057), designed to speed security updates via Intune. While its aim, to help in fast roll‚Äëouts and emergency patches, is good, a flaw in its configuration meant many devices were exposed: attackers could trigger arbitrary code execution remotely.In this post, we‚Äôll walk you through how we found this issue, how Microsoft has responded, and what you can do if your devices are still vulnerable. We‚Äôll cover the original version 1.0, the attack vector we leveraged, evidence from real‚Äëworld telemetry, and how newer versions have tried to plug the gap.After reading WatchTowr‚Äôs deep dive on abandoned AWS S3 buckets earlier this year, we started wondering: how many Azure blob storage accounts could be silently dangling out there, just waiting to be claimed? So, we began looking, and started monitoring DNS traffic on our own Windows machines. And we found more than we expected.Among the pile of findings, which will be covered in later blogs, one stood out: payloadprod0.blob.core.windows.net . This finding kicked off what would become a deep dive into remote code execution through a signed Microsoft tool.Once we registered the storage account (), we began monitoring for inbound requests. Within hours, we were seeing hundreds of HTTP GET requests hitting the blobs, coming from all over the world. These requests targeted structured URIs like:GET /<hash>/enrolled.json  
GET /<hash>/Devices/<hash>.jsonAll with a consistent user agent: . What could that be?Digging deeper, we queried EDR telemetry and found that , a Microsoft-signed binary known as the Update Health Service, was actively resolving these domains across multiple customer environments. This service lived in: C:\Program Files\Microsoft Update Health Tools\uhssvc.exe. Later, we found out that the Azure storage accounts used, followed a predictable naming pattern: payloadprod0.blob.core.windows.net through payloadprod15.blob.core.windows.net. When we checked, 10 of those 15 blobs were still unregistered. So we claimed them and started watching thousands of similar requests flowing in from all over the world.The obvious next step? Figure out what these endpoints were trying to fetch, and whether we could influence what they received.To understand , we first needed to trace how  actually works. Let‚Äôs start with the original version 1.0 of the update health tools. After some reverse engineering, we developed a hypothesis that the team within Microsoft writing this tool, probably needed an easy service to check which updates to install. They apparently decided to use Azure blob storages, with a container per tenant and a few JSON files to specify the configuration.So what does  do, exactly?A new installation will start by checking if it‚Äôs Entra joined/registered. If not, it will simply stop as this is an enterprise tool.The service checks whether this Entra tenant is enrolled into update management by downloading a file from /<tenant_hash>/enrolled.json and checking whether  is set to  in this JSON.If the tenant is enrolled it will continue the process of enrolling itself. This means downloading another JSON from /<tenant_hash>/Devices/<device_id_hash>.json with only a single field containing the policy ID assigned to this computer.After that, the Update Health Tools will start polling /<tenant_hash>/Policies/<policy_id>/<cpu>_<osbuild>.json .It will then look at  to determine what to do.Opening up the binary in IDA gives us an easy list of actions we can specify:Our interest was immediately piqued by the ‚ÄúExecuteTool‚Äù option. That sounds like an easy way to get code execution.Scrolling through the <strong>WSD::ToolExecutor::Execute</strong> function we see our first hurdleIt looks like we can only execute a Microsoft signed binary. Diving a bit deeper, we see that we actually need an executable with an embedded signature that‚Äôs signed by Microsoft. These are more rare, since most default windows executable are signed using catalog files. With catalog files you can sign a list of executables instead of signing each executable individually. This allows Microsoft to optimise checking of signatures and saves disk space.Luckily there‚Äôs an easy target on each windows installation: . But then we hit a new roadblocker.We were excited having found remote code execution in v1.0, and wanted to test it. Unfortunately for us, Microsoft no longer offers version v1.0 from February 2021 for download. Instead, it gives you v1.1 from December 2022. Still determined to get RCE in the latest version, we opened it up in IDA and found a second implementation for getting the config. üòÉNo longer content with using simple Blob Storage, the developers apparently decided to implement a real web service in v1.1 at devicelistenerprod.microsoft.com. Furthermore, they added new storage accounts specifically designed for EU customers and a 2nd copy of the webservice at  and devicelistenerprod.eudb.microsoft.com. We weren‚Äôt able to register any of these storage accounts, nor these domain names.So apparently we won‚Äôt have RCE inside the EU, which means all of our European customers at Eye Security are safe! üòâAfter some more reversing of v1.1, we unlocked the option of re-enabling the old blob storage based communication by setting the configuration parameter  to 1 in the registry. While also allowing us to test from the EU by changing UHS.STORAGEACCOUNTENDPOINTEUDB to a storage account we control.Remote Code Execution (RCE)So, for the old-school experience of popping a calc, we created the following JSON as payload.{
¬† "RequestId": "00000000-0000-0000-0000-000000000001",
¬† "EnterpriseActionType": "ExecuteTool",
¬† "EnterpriseExecutableClientPath": "..\\..\\Windows\\explorer.exe",
¬† "EnterpriseExecutableClientParameters": "/root,C:\\Windows\\system32\\calc.exe",
¬† "EnterpriseExecutableClientPayload": []
}Which produced the expected result when testing:Overall impact of this vulnOf course, we didn‚Äôt try this on any machine we didn‚Äôt own, but we could use the access logs of Azure Blob storage to see how many machines we could have accessed. For this we‚Äôve collected logs for 7 days of traffic to the 10 storage accounts we registered.In that period, we‚Äôve seen  from the Update Health Tools. These are coming from 9.976 unique Azure tenants. Of these, we noticed  asking whether they should enroll. For these requests, we can‚Äôt distinguish whether it‚Äôs a single machine in this tenant or a whole fleet of machines. The devices looking for their configured policy can be individually identified. These are coming from  and .Given the enormous install base of Windows, this is of course a tiny fraction of machines still running the old (1.0) version of Update Health Tools or having the backward compatible flag enabled for the newer version.We reported this vulnerability to Microsoft on July 7 2025 and they confirmed the behavior on July 17. We successfully transferred ownership of these storage accounts to Microsoft on July 18. Therefore all endpoints should be safe now.After seeing what impact this issue had, it‚Äôs of course good to reflect how secure design principles can be used to avoid such issues in the future. The obvious way to avoid such issues is of course to not remove azure storage accounts or domains that publicly released software connects to. You can keep storage accounts reserved and linked to your tenant with all data removed and public access disabled. This makes sure no attacker can register the account, while also providing ease of mind that no data can leak and no unexpected bills will arrive.Looking a bit further into the root cause we see that the developers are confusing transport security with message security. It‚Äôs easy to be tricked into believing that since Microsoft owns the storage account and the certificates for the associated, the data received from the server can be trusted. This only means that the data was securely transmitted from public Azure services. What they should have done is sign the messages themselves. That way no matter who owns the storage account or has the ability to generate SSL certificates, they can still verify that the commands to be executed are signed by the correct Microsoft team.]]></content:encoded></item><item><title>HelixGuard uncovers malicious &quot;spellchecker&quot; packages on PyPI using multi-layer encryption to steal crypto wallets.</title><link>https://helixguard.ai/blog/malicious-spellcheckers-2025-11-19</link><author>/u/Fit_Wing3352</author><category>netsec</category><pubDate>Thu, 20 Nov 2025 03:36:10 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Breaking Oracle‚Äôs Identity Manager: Pre-Auth RCE (CVE-2025-61757)</title><link>https://slcyber.io/research-center/breaking-oracles-identity-manager-pre-auth-rce/</link><author>/u/Mempodipper</author><category>netsec</category><pubDate>Thu, 20 Nov 2025 03:18:43 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item></channel></rss>