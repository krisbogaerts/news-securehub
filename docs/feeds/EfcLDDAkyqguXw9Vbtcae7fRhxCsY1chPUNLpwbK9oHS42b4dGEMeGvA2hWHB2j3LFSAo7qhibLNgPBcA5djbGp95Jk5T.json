{"id":"EfcLDDAkyqguXw9Vbtcae7fRhxCsY1chPUNLpwbK9oHS42b4dGEMeGvA2hWHB2j3LFSAo7qhibLNgPBcA5djbGp95Jk5T","title":"top scoring links : programming","displayTitle":"Reddit - Programming","url":"https://www.reddit.com/r/programming/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/programming/top/?sort=top&t=day&limit=6","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"Where It's at://","url":"https://overreacted.io/where-its-at/","date":1759437408,"author":"/u/steveklabnik1","guid":641,"unread":true,"content":"<p>You might have heard about the AT protocol (if not, <a href=\"https://overreacted.io/open-social/\">read this!</a>)</p><p>Together, all servers speaking the AT protocol comprise —a web of hyperlinked JSON. Each piece of JSON on the atmosphere has its own  URI:</p><p>But where do they point, exactly?</p><p>Given an  URI, how do you locate the corresponding JSON?</p><p>In this post, I’ll show you the exact process of resolving an  URI step by step. Turns out, this is also a great way to learn the details of how  works.</p><p>Let’s start with the structure of a URI itself.</p><p>As you might know, a URI often contains a scheme (for example, ), an  (like ), a path (like ), and maybe a query.</p><p>In most protocols, including , the authority part points at whoever’s  the data. Whoever  this data is either not present, or is in the path:</p><p><strong>The  protocol flips that around.</strong></p><p>In  URIs, whoever  the data is the authority, in the most literal sense:</p><p><strong>The user is the authority for their own data.</strong> Whoever’s  the data could change over time, and is  directly included in an  URI. To find out the actual physical server hosting that JSON, you’re gonna need to take a few steps.</p><p>Let’s try to resolve this  URI to the piece of JSON it represents:</p><p>An easy way to resolve an  URI is to use an <a target=\"_blank\" href=\"https://sdk.blue/\">SDK</a> or a client app. Let’s try an online client, for example, <a target=\"_blank\" href=\"https://pdsls.dev/at://ruuuuu.de/app.bsky.feed.post/3lzy2ji4nms2z\">pdsls</a> or <a target=\"_blank\" href=\"https://atproto.at/viewer?uri=at://ruuuuu.de/app.bsky.feed.post/3lzy2ji4nms2z\">Taproot</a> or <a target=\"_blank\" href=\"https://atproto-browser.vercel.app/at/ruuuuu.de/app.bsky.feed.post/3lzy2ji4nms2z\">atproto-browser</a>. They’ll figure out the physical server where its JSON is currently hosted, and show that JSON for you.</p><p><strong>The above  URI points at this JSON, wherever it is currently being hosted:</strong></p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"js\" data-theme=\"Overnight\"><code data-language=\"js\" data-theme=\"Overnight\"></code></pre></figure><p>You can guess by the  field being  that this is some kind of a post (which might explain why it has fields like  and ).</p><p>However, note that this piece of JSON represents a certain social media post , not a web page or a piece of some app. <strong>It’s pure data as a piece of JSON</strong>, not a piece of UI. You may think of the  stating the data ; the  prefix tells us that the  application might know something about what to do with it. Other applications <a target=\"_blank\" href=\"https://bsky.app/profile/o.simardcasanova.net/post/3luujudlr5c2j\">may also</a> consume and produce data in this format.</p><p>A careful reader might notice that the  in the JSON block is  an  URI but it’s slightly different from the original  URI we requested:</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"js\" data-theme=\"Overnight\"><code data-language=\"js\" data-theme=\"Overnight\"></code></pre></figure><p>In particular, the short  authority has expanded into a longer  authority. Maybe that’s the physical host?</p><p><strong>Actually, no, that’s not the physical host either</strong>—it’s something called an . Turns out, resolving an  URI is done in three distinct steps:</p><ol><li>Resolve the handle to an identity </li><li>Resolve that identity to a hosting </li><li>Request the JSON from that hosting </li></ol><p>Let’s go through each of these steps and see how they work.</p><p>The  URIs you’ve seen earlier are fragile because they use handles.</p><p>Here, , , and  are handles:</p><p>The user may choose to change their  handle later, and it is important for that not to break any links between pieces of JSON already on the network.</p><p>This is why, before you  an  URI, you should turn it into a canonical form by resolving the handle to something that never changes—an . An identity is like an account ID, but global and meant for the entire web. There are two mechanisms to resolve a handle to an identity (also known as a “<a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Decentralized_identifier\">DID</a>”):</p><ol><li>Query the DNS TXT record at  looking for </li><li>Make an HTTPS GET to <code>https://&lt;handle&gt;/.well-known/atproto-did</code></li></ol><p>The thing you’re looking for, the DID, is going to have a shape like . (We’ll revisit what that means later.)</p><p>For example, let’s try to resolve  via the DNS mechanism:</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"sh\" data-theme=\"Overnight\"><code data-language=\"sh\" data-theme=\"Overnight\"></code></pre></figure><p>The  handle  to be owned by , whoever that may be. That’s all that we wanted to know at this point:</p><p><strong>Note this doesn’t  their association yet.</strong> We’ll need to verify that whoever controls the  identity “agrees” with  being their handle. The mapping is bidirectional. But we’ll confirm that in a later step.</p><p>Now let’s try to resolve  using the DNS route:</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"sh\" data-theme=\"Overnight\"><code data-language=\"sh\" data-theme=\"Overnight\"></code></pre></figure><p>That also worked! The  handle claims to be owned by the <code>did:plc:fpruhuo22xkm5o7ttr2ktxdo</code> identity, whoever that may be:</p><p>This DID looks a bit different than what you saw earlier but it’s also a valid DID. Again, it’s important to emphasize we’ve not confirmed the association yet.</p><p>Subdomains like  can also be handles.</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"sh\" data-theme=\"Overnight\"><code data-language=\"sh\" data-theme=\"Overnight\"></code></pre></figure><p>The DNS mechanism didn’t work, so let’s try with HTTPS:</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"sh\" data-theme=\"Overnight\"><code data-language=\"sh\" data-theme=\"Overnight\"></code></pre></figure><p>That worked! This means that  handle claims to be owned by the <code>did:plc:5c6cw3veuqruljoy5ahzerfx</code> identity, whoever that is:</p><p>So you get the idea. When you see a handle, you can probe it with DNS and HTTPS to see if it claims to be owned by some identity (a DID). If you found a DID, you’ll then be able to (1) verify it actually owns that handle, and (2) locate the server that hosts the data for that DID. And that will be the server you’ll ask for the JSON.</p><p><a target=\"_blank\" href=\"https://docs.bsky.app/docs/advanced-guides/resolving-identities\">In practice</a>, if you’re building with AT, you’ll likely want to either deploy your own handle/did resolution cache or hit an existing one. (Here’s <a target=\"_blank\" href=\"https://ngerakines.leaflet.pub/3lyea5xnhhc2w\">one implementation.</a>)</p><p>Now you know how handles resolve to identities, also known as DIDs. Unlike handles, which change over time, DIDs never change—they’re immutable.</p><p>These  links, which use handles, are human-readable but fragile:</p><p>They will break if one of us changes a handle again.</p><p>In contrast, the  links below, which use DIDs, will not break until we either delete our accounts, delete these records, or permanently take down our hosting:</p><p>So, really, this is the “true form” of an  URI:</p><p><strong>Think of  links with DIDs as “permalinks”.</strong> Any application  URIs should store them in this canonical form so that logical links between our pieces of JSON don’t break when we change our handles or change our hosting.</p><p>Now that you know how to resolve a handle to a DID, you want to do two things:</p><ol><li>Verify that whoever owns this DID actually goes by that handle.</li><li>Find the server that hosts all the data for this DID.</li></ol><p>You can do both of these things by fetching a piece of JSON called the . You can think of it as sort of a “passport” for a given DID.</p><p>How you do that depends on what kind of DID it is.</p><p>Currently, there are two kinds of DIDs, known as , supported by the AT protocol:  (a <a target=\"_blank\" href=\"https://w3c-ccg.github.io/did-method-web/\">W3C draft</a>) and  (<a target=\"_blank\" href=\"https://github.com/did-method-plc/did-method-plc\">specified</a> by Bluesky).</p><p>The  handle claims to be owned by :</p><p>To check this claim, let’s find the DID Document for . The <a target=\"_blank\" href=\"https://w3c-ccg.github.io/did-method-web/\"> method</a> is a specification that specifies an <a target=\"_blank\" href=\"https://w3c-ccg.github.io/did-method-web/#read-resolve\">algorithm</a> for that.</p><p>In short, you cut off the  from the DID, append  to the end, and run an HTTPS GET request:</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"sh\" data-theme=\"Overnight\"><code data-language=\"sh\" data-theme=\"Overnight\"></code></pre></figure><p>This DID Document looks sleep-inducing but it tells us three important things:</p><ul><li> The  field confirms that whoever controls  indeed wants to use  as a handle. ✅</li><li><strong>How to verify the integrity of their data.</strong> The  field tells us the public key with which all changes to their data are signed.</li><li><strong>Where their data is stored.</strong> The  field tells us the actual server with their data. Rudy’s data is currently hosted at .</li></ul><p>A DID Document really  like an internet passport for an identity: here’s their handle, here’s their signature, and here’s their location. It connects a handle to a hosting while letting the identity owner change  the handle  the hosting.</p><p>Users who interact with  on different apps in the atmosphere don’t need to know or care about his DID  about his current hosting (and whether it moves). From their perspective, his current handle is the only relevant identifier. As for developers, they’ll refer to him by DID, which conveniently never changes.</p><p>All of this sounds great, but there is one big downside to the  identity. If  ever loses control of the  domain, he will lose control over his DID Document, and thus over his entire identity.</p><p>Let’s have a look at an alternative to  that avoids this problem.</p><p>We already know the  handle claims to be owned by the <code>did:plc:fpruhuo22xkm5o7ttr2ktxdo</code> identity (actually, that’s me!)</p><p>To check this claim, let’s find the DID Document for <code>did:plc:fpruhuo22xkm5o7ttr2ktxdo</code>.</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"sh\" data-theme=\"Overnight\"><code data-language=\"sh\" data-theme=\"Overnight\"></code></pre></figure><p>The DID Document itself works exactly the same way. It specifies:</p><ul><li> The  field confirms that whoever controls <code>did:plc:fpruhuo22xkm5o7ttr2ktxdo</code> uses  as a handle. ✅</li><li><strong>How to verify the integrity of my data.</strong> The  field tells us the public key with which all changes to my data are signed.</li><li> The  field tells us the actual server with my data. It’s currently at <code>https://morel.us-east.host.bsky.network</code>.</li></ul><p>Although my handle is , the actual server storing my data is currently <code>https://morel.us-east.host.bsky.network</code>. I’m happy to keep hosting it there but I’m thinking of moving it to a host I control in the future. I can change both my handle and my hosting without disruption to my social apps.</p><p>Unlike Rudy, who has a  identity, I stuck with  (which is the default one when you create an account on Bluesky) so that I’m not irrecovably tying myself to any web domain. “PLC” officially stands for a “Public Ledger of Credentials”—essentially, it is like an npm registry but for DID Documents. (Fun fact: originally PLC meant “placeholder” but they’ve decided <a target=\"_blank\" href=\"https://www.youtube.com/watch?v=m9AVUAUDC2A\">it’s a good tradeoff.</a>)</p><p>The upside of a  identity is that I can’t lose my identity if I forget to renew a domain, or if something bad happens at the top level to my TLD.</p><p>The downside of a  identity is that whoever operates the PLC registry has some degree of control over my identity. They can’t outright  it because every version is recursively signed with the hash of the previous version, every past version is queryable, and the hash of the initial version  the DID itself.</p><p>So far, you’ve learned how to:</p><ul><li>Resolve a handle to a DID.</li><li>Grab the DID Document for that DID.</li></ul><p>That actually tells you enough to get the JSON by its  URI!</p><p>Each DID Document includes the  which is the actual hosting.  the service you can hit by HTTPS to grab any JSON record it stores.</p><p>For example, the  handle resolves to , and its DID Document has a  pointing at .</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"sh\" data-theme=\"Overnight\"><code data-language=\"sh\" data-theme=\"Overnight\"></code></pre></figure><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"json\" data-theme=\"Overnight\"><code data-language=\"json\" data-theme=\"Overnight\"></code></pre></figure><ul><li>The  handle resolves to <code>did:plc:fpruhuo22xkm5o7ttr2ktxdo</code>.</li><li>The DID Document for <code>did:plc:fpruhuo22xkm5o7ttr2ktxdo</code> points at <code>https://morel.us-east.host.bsky.network</code> as the current hosting.</li></ul><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"sh\" data-theme=\"Overnight\"><code data-language=\"sh\" data-theme=\"Overnight\"></code></pre></figure><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"json\" data-theme=\"Overnight\"><code data-language=\"json\" data-theme=\"Overnight\"></code></pre></figure><p>And that’s how you resolve an  URI.</p><p><em>Exercise: In the record above, the  is a link to another record. Figure out the handle of its owner and the contents of that record. Use <a target=\"_blank\" href=\"https://pdsls.dev/\">pdsls</a> to check your answer.</em></p><p>To resolve an arbitrary  URI, you need to follow three steps:</p><ol><li>Resolve the handle to an identity (using DNS and/or HTTPS).</li><li>Resolve that identity to a hosting (using the DID Document).</li><li>Request the JSON from that hosting (by hitting it with ).</li></ol><p>If you’re building a client app or a small project, an <a target=\"_blank\" href=\"https://sdk.blue/\">SDK</a> will handle all of this for you. However, for good performance, you’ll want to hit a resolution cache instead of doing DNS/HTTPS lookups on every request. <a target=\"_blank\" href=\"https://quickdid.smokesignal.tools/\">QuickDID</a> is one such cache. You can also check out the <a target=\"_blank\" href=\"https://tangled.org/@pdsls.dev/pdsls/blob/main/src/utils/api.ts\">pdsls source</a> to see how exactly it handles resolution.</p><p>In practice, a lot of apps don’t end up needing to resolve  URIs or load JSON records because they  data from the network <a target=\"_blank\" href=\"https://pdsls.dev/jetstream?instance=wss%3A%2F%2Fjetstream1.us-east.bsky.network%2Fsubscribe\">via a websocket</a> and aggregate it in a local database. If that’s your approach, you’ll still use the  URIs as unique identifiers for user-created data, but the data itself will get pushed to you rather than pulled by you. Still, it’s useful to know that you  fetch it on demand.</p><p>The AT protocol is fundamentally an abstraction over HTTP, DNS, and JSON. But by standardizing how these pieces fit together—putting the user in the authority position, separating identity from hosting, and making data portable—it turns the web into a place where <a href=\"https://overreacted.io/open-social/\">your content belongs to you</a>, not to the apps that display it.</p><p>There’s more to explore in the atmosphere, but now you know where it’s .</p>","contentLength":11268,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1nwf92e/where_its_at/"},{"title":"Developing a BASIC language interpreter in 2025","url":"https://nanochess.org/ecs_basic.html","date":1759428939,"author":"/u/ketralnis","guid":640,"unread":true,"content":"<img src=\"https://nanochess.org/img/ecsbasic_1.jpg\" align=\"right\" vspace=\"5\" hspace=\"10\" width=\"50%\" alt=\"Mattel Electronics Intellivision along the ECS running Jetsons\"><div>\nRecently, I had the chance to get an Intellivision II console along the ECS (Entertainment Computer System) and keyboard. I found and typed a game <a href=\"http://spatula-city.org/~intvlib/inty/ecsbasic.html\">Bomb Run 1</a>, using its integrated BASIC language, and I was pretty surprised to see <a href=\"https://forums.atariage.com/topic/384664-typing-basic-on-my-ecs/#findComment-5719486\">how incredibly slow is it</a>.\n</div><div>\nApparently, Mattel Electronics only <a href=\"https://history.blueskyrangers.com/hardware/ecs.html\">developed the ECS</a> to avoid paying a daily penalty of $10,000 dollars to the USA government because they were advertising a keyboard component that wasn't yet available. They developed the ECS in secret, while putting all their money in the ill-fated Keyboard Component which was a full 6502 computer around the Intellivision with an officially licensed MS-Basic.\n</div><div>\nAfter getting the ECS on sale, Mattel forgot completely about it. It is a shame, because the keyboard is reasonable enough, it looks nice, and it could have been a nice starter BASIC platform.</div><div>\n    Anyway, the turtle speed intrigued me as I was pretty convinced that the Intellivision processor could do faster floating-point, so why not write my own extended BASIC interpreter?\n</div><div>\n    For the remaining of this article, the original Mattel ECS BASIC will be simply called ECS BASIC.\n</div><div>\nThe implementation of my extended BASIC interpreter is for a General Instruments CP1610 processor. This is a 16-bit processor introduced in 1975, with a resemblance to the PDP-11. However, General Instruments didn't allowed second sources, only wanted big orders, and ignored small requests (basically shooting itself in the foot), and this processor was used widely only in the Mattel Intellivision, and it ceased production in 1985 at the same time of the Intellivision demise.\n</div><div>\nA full documentation of the instruction set is available along the jzintv emulator that can be downloaded from <a href=\"http://spatula-city.org/~im14u2c/intv/\">http://spatula-city.org/~im14u2c/intv/</a>.</div><div>I'll be using the basic 8K words between $5000-$6fff for the BASIC language, and I'll ignore altogether the EXEC (the Intellivision BIOS) and the ECS ROMs (I didn't even bother disabling it).</div><div>\n    I never coded a full BASIC language before, because it was not needed. In the eighties, I had access to a Z80 BASIC that was already ported to the homebrew computer I was using, and in the nineties, I managed to put floating-point in the <a href=\"https://nanochess.org/emulator.html\">Li-Chen Wang's Tiny BASIC</a>, do some statement extensions for it, and also tried to do a tokenized BASIC, but I never went too far.\n</div><div>\nI started in Sep/17/2025 by coding a floating-point addition subroutine. I didn't had a format in mind, it only had to be 32-bit because the CP1610 registers are 16-bit, so two registers fit nicely for keeping a floating-point number, and another two for the second operand.\n</div><div>\nThe format was decided in the basis of how so easy was to extract the sign, exponent, and the mantissa with 16-bit operations, as 8-bit operations are difficult to do. This automatically discarded an IEEE-754 compatible format, and I settled for a format based on a 24-bit mantissa in the higher bits, followed by the sign bit, and the exponent in the lower 7 bits. The exponent is a bit smaller than the classic IEEE-754, but we get an extra precision bit.\n</div><div>\n    The code for extracting the mantissa is pretty short:\n</div><pre><small>\n    ANDI #$FF00,R1  ; Remove the sign and exponent.\n    SETC\n    RRC R0,1        ; Insert the top bit of the mantissa (fixed one)\n    RRC R1,1        ; Now we have a 25-bit mantissa,\n                    ; aligned at the higher bit.\n</small></pre><div>\n    I didn't define denormalized numbers, nor infinity and NaN (Not a Number), because this wasn't supported in the BASIC interpreters of the eighties.\n</div><div>\n    It was easy to get the subtraction routine once I got the addition subroutine working, because you only need to flip the sign bit in the second operand.\n</div><div>\n    I did later the multiplication routine, but I stumbled over a problem where sometimes the mantissa overflowed. I simply added a very complicated code to move the mantissa by one bit. It was several days later when I studied it, and I discovered you can only have a result of x+y-1 bits or x+y bits (where x is the number of significant bits in the first operand, and y is the number of significant bits in the second operand), and I could optimize it by simply inserting an extra zero bit at the left to account for the carry.\n</div><div>\n    Of course, I made a small test program to check for the validity of the arithmetic operations with several cases. It took me four days to code the fully functional floating-point library.\n</div><div>\nI couldn't start a BASIC interpreter without the keyboard reading code, and terminal-style output. Fortunately, Joe Zbiciak (intvnut) already had developed routines for reading the ECS keyboard, and I integrated these with a ROM header, adding along terminal handling for displaying letters, scrolling the screen, and moving the cursor. \n</div><div>\n    With all this integrated I had a dumb terminal working, you type anything on the keyboard, and you get the same keys displayed on the screen. This was Sep/19/2025.\n</div><div>\n    The CP1610 processor cannot address directly the internal memory in byte terms, instead everything is handled by full words. I had to take this in account for my tokenized BASIC representation. A standard Intellivision doesn't have enough memory for a BASIC interpreter, so the ECS BASIC included 2K of 8-bit RAM.\n</div><div>\n    However, a few years ago, the JLP-Flash cartridge was manufactured and it provides 8K of 16-bit RAM over $8000-$9fff, so for my extended BASIC this was excellent.\n</div><div>\n    When I talk about tokenization, I mean that all the language's reserved words are represented with a token. This speeds up the execution of the language, as it doesn't have to run a word match each time.\n</div><div>\n    My first version of the internal representation for BASIC lines was the line number as a word, followed by a pointer to the next line, followed by the tokenized BASIC code for the line, ended with a zero word.\n</div><div>\n    As I coded the line insertion routines in Sep/22/2025, I discovered the pointer to the next line wasn't a good idea, because it needed to move  pointer after a line insertion. Instead, I converted the pointer into a length (the number of words used by the tokenized line). This allowed for a very compact code to jump over lines:\n</div><pre><small>\n    INCR R4     : Jump over the line number.\n    ADD@ R4,R4  ; Add the tokenized length to the current pointer\n                ; Et voila! It jumped over the line.\n</small></pre><div>\n    With the line insertion routines completed, I went to implement the BASIC tokenization subroutine. I decided against handling tokenization byte-per-byte, and instead made each token a word. Of course, it is wasted space if you are using strings, but it is faster on execution. Token numbers start at $0100. It only remained to interface the input with the new routines.\n</div><div>\n    I decided to read the text directly from the screen, very unplanned, and probably buggy, but it has worked for the current time. And maybe later I'll extend it for a full-screen editor.\n</div><pre><small>\nkeywords:\n\tDECLE \":\",0\t; $0100\n\tDECLE \"LIST\",0\n\tDECLE \"NEW\",0\n\tDECLE \"CLS\",0\n\tDECLE \"RUN\",0\t; $0104\n\tDECLE \"STOP\",0\n\tDECLE \"PRINT\",0\n\tDECLE \"INPUT\",0\n\tDECLE \"GOTO\",0\t; $0108\n\tDECLE \"IF\",0\n\tDECLE \"THEN\",0\n\tDECLE \"ELSE\",0\n\tDECLE \"FOR\",0\t; $010C\n\tDECLE \"TO\",0\n\tDECLE \"STEP\",0\n\tDECLE \"NEXT\",0\n\tDECLE \"GOSUB\",0\t; $0110\n</small></pre><div>Excerpt of the tokenization table.</div><div>\n    Now I was able to edit, correct, and delete BASIC code lines. The next logical step was the execution of the program. I implemented  by reading each program line sequentially, and each token found choose directly the command to execute.\n</div><div>\n    My first program was simply  and I was happy when I typed  and the screen was cleared.\n</div><div>\n    This was followed shortly by  and . Where  was only capable of putting a string on the screen, and  changed the execution flow. I added a check for the Esc key to exit an infinite loop.\n</div><div>\n    I was also pretty impatient to see if my extended BASIC language was speedier than the ECS BASIC, so I decided to implement , and a small expression parser supporting the relational operators, and the basic arithmetic operators (, ,  and ), along numbers and variables.\n</div><div>\n    The numbers were simply read as integers and converted to floating-point format, while the variables used 26 double-word memory spaces covering the A to Z variables.\n</div><div>\n    In order to create a loop, it was required to implement variable assignment.\n</div><pre><small>\n    10 A=1\n    20 PRINT \"Hello\"\n    30 A=A+1\n    40 IF 6&gt;A THEN 20\n</small></pre><div><img src=\"https://nanochess.org/img/ecsbasic_3.png\" vspace=\"5\" hspace=\"10\" width=\"80%\" alt=\"The tokenization of the BASIC program.\">\nThe tokenization of the BASIC program.\n</div><div>\n    For some reason, I couldn't type the less-than operator with the emulated ECS keyboard. Later, I discovered that intvnut missed the character in the Shift table, and it was a matter of a simple fix.\n</div><div>It was past midnight when I finally could try the <a href=\"https://forums.atariage.com/topic/284474-ecs-basic-color-coding-patent/#comment-4145747\">benchmark</a>. As I didn't had yet a  statement, I had to replicate it using increment and comparison.\n</div><div>I ran it, and I was amazed when I discovered it took only 15 seconds. In the ECS BASIC it takes 210 seconds! There are screenshots of the programs in the git.\n</div><h2>More floating-point curiosities</h2><div>\n    This wasn't the first time I programmed a floating-point package. My first one was for a Z80-based computer, I don't remember if it was complete, if it had bugs, or if it was actually used. What I can remember is that I was never able to make a proper subroutine for displaying floating-point numbers. I got stuck with a simple conversion to integer, and printing the integer. \n</div><div>\n    The display of a number followed by fraction and exponent, for me was closer to black magic than anything. I believed that a single routine did everything, but I was wrong. And I came to illumination by reading a Commodore 64 BASIC manual, it says something like numbers in this range are displayed complete, while in other cases the number will be displayed in exponent format.\n</div><div>\n    This triggered a pattern in my mind: If the whole integer fits in the mantissa, display it alongside a small fraction, and if the number doesn't fit, make it bigger or smaller so it fits in an integer, and this one can be displayed in exponent format.\n</div><div>\n    The algorithm is as follows:\n</div><ol><li>\n        The 25-bit mantisa allows integers up from 0 to 33554431. We limit it to the biggest integer all nines, or 9999999.\n    </li><li>\n        If the floating-point number is less than 10,000,000 then the integer part is displayed, and then it gets 2 fraction digits.\n    </li><li>\n        If the floating-point number is less than 0.01 then it is multiplied until it reachs the range 1,000,000 - 9,999,999. The first digit will be the integer part, the following digits will be the fractional part, and the exponent will be displayed along.\n    </li><li>\n        If the floating-point number is greater than 9,999,999 then it is divided by 10 until it fits the same range. And again display like in step 3.\n    </li></ol><div>\n    And this way, thirty years later, I discovered printing floating-point numbers isn't so obscure as I believed, but indeed it has a lot of magic.\n</div><div>\n    The statements  allow to create small subroutines, and these have their own stack to keep track of where to return (a pointer plus the line number)\n</div><div>\nThe  loop is one of the most known statements of the core BASIC language. Implementing this required a redesign of my execution loop, because I was doing it line-by-line, but the  changed the line, but on the next statement it would lost track and get back to the line following the .\n</div><div>\nThe loops also require their own stack, but including the counter variable address, a pointer to the  expression, and a pointer to the  expression (5 words in total)\n</div><div>\nThe  statement was replaced with a code that runs sequentially over the tokens, and jumps over the line headers. This way is easier to change the execution flow to a new token.\n</div><div>\nI also added the negation operator (required for ) and some functions like , , , and . The  function in particular allows to create little games for guessing numbers, and so.\n</div><div>\nChecking against the ECS BASIC, I was only missing , , and . So I bite the bullet to implement these. Adding along .\n</div><div> for creating arrays was pretty easy, and I adjusted all the variable access paths of the interpreter in a way that any indexed access is the same as accessing a normal variable.\n</div><div>\nAt this point, my extended BASIC language was already orders of magnitude faster than the ECS BASIC, and it could be used to write little text games (well, using only numbers)\n</div><div>\nHowever, it didn't handled yet the controllers, sound, graphics, and sprites. The ECS BASIC had some statements for it, but the sprites cannot be defined, and instead these had to be \"grabbed\" from a game cartridge. Of course, the user was limited to these game sprites. Also positioning sprites was done with multiple variable assignments in an array-like style of access.\n</div><div>\nFor my extended BASIC I decided for a kind of advanced statements patterned after the ones from my <a href=\"https://nanochess.org/intybasic.html\">compiled IntyBASIC language</a> but not exactly the same:\n</div><ul><li> for setting the color stack mode.</li><li> for setting the foreground/background mode.</li><li> for defining GRAM cards.</li><li> for setting the paint color used in .</li><li> for displaying a sprite on the screen.</li><li> for waiting the next video frame.</li><li> for accessing the sound chip.</li><li> for reading the 16 disc directions.</li><li> for reading the side-buttons.</li><li> for reading the keypad.</li><li> for accesing the screen.</li></ul><div>\nOnce these were implemented, I started coding a minimal game to test the interpreter, and I called it UFO Invasion. Of course, I found a few bugs in my interpreter and fixed them.\n</div><div>\nThe game was working, and at a reasonable speed. What about testing in real hardware? I loaded the interpreter into a LTO-Flash cartridge and connected my ECS system.\n</div><div>\nMy first attempt crashed continuously. I lost half an hour looking for errors, until I noticed  crashed the interpreter. I had forgot to enable the extra RAM of the JLP cartridge. And finally it worked!\n</div><div>\nTyping the program was difficult, as the keyboard bounced a lot. This happens when you read too fast the keyboard, so fast you can see that effectively the key contact isn't perfect. I had to add a small wait before reading the keyboard, and it solved most of the problems.\n</div><div>\n    At the end, my extended BASIC interpreter was coded in six days! I think it is way faster when you are enjoying programming it.\n</div><pre><small>10 CLS:REM UFO INVASION. NANOCHESS 2025\n20 DEFINE 0,\"183C00FF007E3C000018183C3C7E7E000000183C3C3C3C7EFF2400\"\n50 x=96:w=0:v=0:u=0:t=159\n60 SPRITE 0,776+x,344,2061\n70 SPRITE 1,776+v,256+w,2066\n80 SPRITE 2,1796+t,256+u,6149\n90 WAIT:c=STICK(0)\n100 IF c&gt;=3 AND c&lt;=7 THEN IF x&lt;152 THEN x=x+4\n110 IF c&gt;=11 AND c&lt;=15 THEN IF x&gt;0 THEN x=x-4\n120 IF w=0 THEN SOUND 2,,0:IF STRIG(0) THEN v=x:w=88\n130 t=t+5:IF t&gt;=160 THEN t=0:u=INT(RND*32)+8\n140 IF w THEN SOUND 2,w+20,12:w=w-4:IF ABS(w-u)&lt;8 AND ABS(v-t)&lt;8 THEN\n    t=164:w=0:SOUND 3,8000,9:SOUND 1,2048,48\n150 GOTO 60\n</small></pre><div><img src=\"https://nanochess.org/img/ecsbasic_4.jpg\" vspace=\"5\" hspace=\"10\" width=\"40%\" alt=\"UFO Invasion running on the Mattel Intellivision ECS\"><img src=\"https://nanochess.org/img/ecsbasic_5.jpg\" vspace=\"5\" hspace=\"10\" width=\"40%\" alt=\"Partial listing of UFO Invasion on the Mattel Intellivision ECS\">\nUFO Invasion running on the Mattel Intellivision ECS, and a partial listing of the game.\n</div><div>\nA big difference against \"standard\" BASIC is the lack of proper strings. In the ECS BASIC, you could read a string from the keyboard using GET, and put it again on the screen using PUT, but that was all.\n</div><div>\nAdding the support for standard strings would mean it could run some text-processing programs like Eliza in BASIC, and some other small games could be easily translated.\n</div><div>\nThis was one of the portability things that the BASIC language had at the time, and it was used by many books in a way that the programs were written with that \"core\" BASIC language in mind, and these could be typed into almost any computer with a decent interpreter.\n</div><div>\nThe source code is released at <a href=\"https://github.com/nanochess/ecsbasic\">https://github.com/nanochess/ecsbasic</a>. I tried to release it so early as possible, so you can get a glance of how it was growing in the commits.\n</div><div>\nEnjoy it! </div><div>After publishing this article in Sep/28/2025, several people pointed to me that I didn't explained why the ECS BASIC was so slow. Truth to be told, I was so happy with my working extended BASIC that I didn't even bother to look more on the ECS BASIC.</div><div>First and all, there is a thread in Atariage about the <a href=\"https://forums.atariage.com/topic/284474-ecs-basic-color-coding-patent/\">ECS BASIC Color Patent</a>, and the <a href=\"https://forums.atariage.com/topic/284474-ecs-basic-color-coding-patent/#findComment-4145393\">eighth post</a> also by intvnut explains in great detail how he disassembled the code and found a terrible way of doing a shift of the floating-point accumulator.</div><div>However, there are a few other details that make it slow. For example, the extra RAM is 2K of , and all the Intellivision memory accesses are for 16 bits (one word), so every single access to variables requires the SDBD instruction. This instruction tells the CP1610 processor to read the word in two steps.</div><div>I did my own disassembly, and after giving a look around the same zone disassembled by intvnut, I found this code that extracts the exponent of a floating-point number:</div><pre><small>\n $E1DD: PSHR R5                                     \n $E1DE: MVI@ R1,R2                                  \n $E1DF: ANDI #$007F,R2                              \n $E1E1: MOVR R2,R5                                  \n $E1E2: ANDI #$0040,R5                              \n $E1E4: BNEQ $E1E8                                  \n $E1E6: NEGR R2                                     \n $E1E7: PULR R7                                     \n $E1E8: XORI #$0040,R2                              \n $E1EA: PULR R7                                     \n</small></pre><div>It extracts the seven bits of the exponent. In the range $00-$3f makes it negative, and the range $40-$7f is converted to $00-$3f. So simply reading the exponent takes 7 instructions. Whoever developed this code didn't take in account that you could save the exponent in two's complement format offset by $40, and it is used nine times.</div><div>For comparison, my code for extracting the exponent is simply .</div><div>It gets worst when I found the code calling $E1DD, and it is for extracting two exponents and doing a comparison between both:</div><pre><small>\n $E147: PSHR R5                                     \n $E148: MOVR R3,R1                                  \n $E149: JSR  R5,$E1DD                               \n $E14C: MOVR R2,R0                                  \n $E14D: MOVR R4,R1                                  \n $E14E: JSR  R5,$E1DD                               \n $E151: CMPR R0,R2                                  \n $E152: BEQ  $E159                                  \n $E154: BMI  $E15B                                  \n $E156: MVII #$0001,R0                              \n $E158: PULR R7                                     \n $E159: CLRR R0                                     \n $E15A: PULR R7                                     \n $E15B: CLRR R0                                     \n $E15C: DECR R0                                     \n $E15D: PULR R7                                     \n</small></pre><div>My code for exponent comparison is composed of only three instructions (two AND and one CMPR) This big code would be kind of reasonable if it wasn't for the fact that it is only called , and it is by the floating-point addition subroutine starting at $E059:</div><pre><small>\n $E067: CLRR R0                                     \n $E068: SDBD                                        \n $E069: MVII #$47D4,R3                              \n $E06C: MOVR R3,R4                                  \n $E06D: SUBI #$0007,R4                              \n $E06F: JSR  R5,$E147                               \n $E072: TSTR R0                                     \n $E073: BEQ  $E081                                  \n $E075: MOVR R4,R1                                  \n $E076: TSTR R0                                     \n $E077: BMI  $E07B                                  \n $E079: ADDI #$0007,R1                              \n $E07B: CLRR R0                                     \n $E07C: JSR  R5,$E15E                               \n $E07F: B    $E067                                  \n</small></pre><div>This routine calls the exponent comparison at $E06F, and if both are equal it jumps out to $E081, else it adjusts the exponent of one number, and  the comparison (notice the B $E067 instruction) The mantissa shifting routine at $E15E operates shifting in steps of 4 bits.</div><div>At $E081 (not shown), it checks the sign of the second operand, and if it is negative, it calls $E194 to do a negation of the number.</div><div>At $E091 it does the addition of the two numbers calling $E1C0, and calls $E183 to check if both signs are equal.</div><div>The code at $E0A4 reinserts the exponent in a very slow way, and it ends by calling $E21A to normalize the floating-point number, again shifting the mantissa in steps of 4 bits.</div><div>It has been just too much code yet, but let's look at the shifting routine:</div><pre><small>\n $E238: MVI@ R1,R2                                  \n $E239: MOVR R2,R5                                  \n $E23A: ANDI #$000F,R2                              \n $E23C: SLL  R2,2                                   \n $E23D: SLL  R2,2                                   \n $E23E: XORR R4,R2                                  \n $E23F: MVO@ R2,R1                                  \n $E240: MOVR R5,R2                                  \n $E241: ANDI #$00F0,R2                              \n $E243: SLR  R2,2                                   \n $E244: SLR  R2,2                                   \n $E245: MOVR R2,R4                                  \n $E246: DECR R1                                     \n $E247: SDBD                                        \n $E248: CMPI #$47CD,R1                              \n $E24B: BNEQ $E238                                  \n</small></pre><div>It takes a byte, shifts it left 4 bits, inserts the carry, and copies the extra 4 bits as the new carry. I couldn't resist showing how it could be made a lot smaller and faster this way:</div><pre><small>\nLE238:\n    MVI@ R1,R2  ; R2 = 0x00ff\n    SLL R2,2\n    SLL R2,2    ; R2 = 0x0ff0\n    XORR R4,R2  ; R2 = 0x0ff0 + carry\n    MVO@ R2,R1  ; This saves the low byte.\n    SWAP R2     ; R2 = 0xf00f\n    ANDI #$000F,R2\n    MOVR R2,R4  ; R4 = 0x000f\n    DECR R1\n    SDBD\n    CMPI #$47CD,R1\n    BNEQ LE238\n</small></pre><div>This saves four instructions in the loop, and it is faster.</div><div>The ECS BASIC has a mantissa of six bytes, so it has more precision than my extended BASIC (three bytes), but it is done in a very slow way!</div><div>For sure the ECS BASIC could be optimized to run at least two times faster.</div><div>Ok, but I haven't yet answered a simple question. How many cycles takes adding 3.0 and 7.0?</div><div>I ran the jzintv emulator with this command line (remember we need a game cartridge so the ECS BASIC works):</div><pre><small>./jzintv -d -s1 -z3 Basketball.bin</small></pre><div>I entered the R command to make it run the ECS BASIC. When I reached the ECS BASIC, I typed PRIN 3+7 and before pressing Enter, I went to the debugger window and pressed Ctrl+C. Then I put breakpoints at selected places (start of the floating-point addition, the place where it calls the addition, and the return instruction):</div><div>Again, I typed the R command, using along M47C0 to watch the memory addresses where floating-point addition happened until I saw the numbers 3 and 7.</div><div>I took note of the cycle number at the right. The operation 3+7 takes exactly 1558 cycles. By the way, the interpreter executes further three floating point additions when processing the numbers, and another two for displaying the number.</div><div><img src=\"https://nanochess.org/img/ecsbasic_6.png\" vspace=\"5\" hspace=\"10\" width=\"80%\" alt=\"jzintv debug window with the ECS BASIC\">\njzintv debug window with the ECS BASIC. The cycle count at the right shows how much time takes a floating-point addition.\n</div><div>Now, let's do the same with my extended BASIC interpreter.</div><div>After assembling with as1600, I generate a .lst file where I searched for the  label (start) and  label (return) The addresses are $61d1 and $625b.</div><div>I ran again the jzintv emulator with the debugging option, and I typed PRINT 3+7, and before pressing Enter, I stopped the debugger using Ctrl+C, and I setup these breakpoints:</div><div>Then I entered the command R, and pressed Enter on the BASIC screen. It took me four R commands to see the values 3 and 7 in the registers, and the result 10.</div><div>And the total cycles used were 479. This means that only in the floating-point addition the Mattel ECS BASIC is five times slower.</div><div><img src=\"https://nanochess.org/img/ecsbasic_7.png\" vspace=\"5\" hspace=\"10\" width=\"80%\" alt=\"jzintv debug window with my extended ECS BASIC\">\njzintv debug window with my extended ECS BASIC. The cycle count at the right shows how much time takes a floating-point addition.\n</div><div>Last modified: Sep/29/2025</div>","contentLength":23794,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1nwbgi9/developing_a_basic_language_interpreter_in_2025/"},{"title":"In C++ modules globally unique module names seem to be unavoidable","url":"https://nibblestew.blogspot.com/2025/09/in-c-modules-globally-unique-module.html","date":1759428726,"author":"/u/ketralnis","guid":639,"unread":true,"content":"<p>Writing out C++ module files and importing them is awfully complicated. The main cause for this complexity is that the C++ standard can not give requirements like \"do not engage in Vogon-level stupidity, as that is not supported\". As a result implementations have to support anything and everything under the sun. For module integration there are multiple different approaches ranging from custom on-the-fly generated JSON files (which neither Ninja nor Make can read so you need to spawn an extra process per file just to do the data conversion, but I digress) to custom on-the-fly spawned socket server daemons that do something. It's not really clear to me what.</p><p>Instead of diving to that hole, let's instead approach the problem from first principles from the opposite side.</p><p>A single project consists of a single source tree. It consists of a single executable E and a bunch of libraries L1 to L99, say. Some of those are internal to the project and some are external dependencies. For simplicity we assume that they are embedded as source within the parent project. All libraries are static and are all linked to the executable E.</p><p>With a non-module setup each library can have its own header/source pair with file names like  and . All of those can be built and linked in the same executable and, assuming their symbol names won't clash, work just fine. This is not only supported, but in fact quite common.</p><p>The dream, then, is to convert everything to modules and have things work just as they used to.</p><p>If all libraries were internal, it could be possible to enforce that the different util libraries get different module names. If they are external, you clearly can't. The name is whatever upstream chooses it to be. There are now two modules called &nbsp;in the build and it is the responsibility of someone (typically the build system, because no-one else seems to want to touch this) to ensure that the two module files are exposed to the correct compilation commands in the correct order.</p><p>This is complex and difficult, but once you get it done, things should just work again. Right?</p><p>That is what I thought too, but that is actually not the case. This very common setup does not work, and to work. You don't have to take my word for it, <a href=\"https://gcc.gnu.org/bugzilla/show_bug.cgi?id=121963\">here is a quote from the GCC bug tracker</a>:</p><blockquote><p>This is already <a href=\"https://eel.is/c++draft/module.unit#2\">IFNDR</a>, and can cause standard ODR-like issues as the name of the module is used as the discriminator for module-linkage entities and the module initialiser function.&nbsp; Of course that only applies if both these modules get linked into the same executable;</p></blockquote><p>IFNDR (ill-formed, no diagnostic required) is a technical term for \"if this happens to you, sucks to be you\". The code is broken and the compiler is allowed to whatever it wants with it (including s.</p><p>What does it mean in practice?</p><p>According to my interpretation of thiscomment (which, granted, might be incorrect as I am not a compiler implementer) if you have an executable and you link into it any code that has multiple modules with the same name, the end result is broken. It does not matter how the same module names get in, the end result is broken. No matter how much you personally do not like this and think that it should not happen, it will happen and the end result is broken.</p><p>At a higher level this means that this property forms a namespace. Not a C++ namespace, but a sort of a virtual name space. This contains all \"generally available\" code, which in practice means all open source library code. As that public code can be combined in arbitrary ways it means that if you want things to work, <i>module names must be globally unique</i> in that set of code (and also in every final executable). Any duplicates will break things in ways that can only be fixed by renaming all but one of the clashing modules.</p><p>Globally unique modules names is thus not a \"recommendation\", \"nice to have\" or \"best practice\". It is a  that comes directly from the compiler and standard definition.</p><p>If we accept this requirement and build things on top of it, things suddenly get a lot simpler. The build setup for modules reduces to the following for projects that build all of their own modules:</p><ul><li>At the top of the build dir is a single directory for modules (GCC already does this, its directory is called )</li><li>All generated module files are written in that directory, as they all have unique names they can not clash</li><li>All module imports are done from that directory</li><li>Module mappers and all related complexity can be dropped to the floor and ignored</li></ul>Importing modules from the system might take some more work (maybe copy Fortran and have a  flag for module search paths). However at the time of writing GCC and Clang module files are not stable and do not work between different compiler versions or even when compiler flags differ between export and import. Thus prebuilt libraries can not be imported as modules from the system until that is fixed. AFAIK there is no timeline for when that will be implemented.<p>So now you have two choices:</p><ol><li>Accept reality and implement a system that is simple, reliable and working.</li><li>Reject reality and implement a system that is complicated, unreliable and broken.</li></ol>[Edit, fixed quote misattribution.]","contentLength":5154,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1nwbd4z/in_c_modules_globally_unique_module_names_seem_to/"},{"title":"Distracting software engineers is way more harmful than most managers think","url":"https://workweave.dev/blog/distracting-software-engineers-is-more-harmful-than-managers-think-even-in-the-ai-times","date":1759422250,"author":"/u/zaidesanton","guid":644,"unread":true,"content":"<p>Our work culture changed mainly for the better after COVID-19, but there were also some negative changes - like an increase of 13.5% in the amount of meetings per employee.[1]</p><p>The problem is that there's a huge gap between how managers think about meetings versus how engineers think about them.</p><p>In the famous “Maker’s Schedule, Manager’s Schedule” [2], Paul Graham wrote:</p><p><em>“When you're operating on the maker's schedule, meetings are a disaster. A single meeting can blow a whole afternoon, by breaking it into two pieces each too small to do anything hard in.”</em></p><p>This problem hasn't gone away with AI coding tools - it's getting worse, as managers assume engineers can now be productive in smaller time chunks.</p><p>Over the past 2 years, we've studied hundreds of engineering teams to understand what the best ones do differently. In this article, we'll share their strategies and actionable steps you can use today. </p><p>But first, let’s talk about deep work: </p><p>The term was coined by Cal Newport, in <em>Deep Work: Rules for Focused Success in a Distracted World</em>book [3].</p><p>Deep Work is the kind of work that requires a big part of your brain power and usually gives some unique value. It can’t be done while distracted! If you can do a task during a Zoom call, it means it’s NOT deep work.</p><p> is the opposite - things you can do without engaging 100% of your brain. Things like answering Slack messages/emails, reviewing a document, and so on.</p><p>Software engineering used to be a haven for people who enjoy deep work. There is a reason why some people still think that software engineers work alone with their headphones in the basement.</p><p>Today it’s becoming harder and harder to get those ‘Deep Work’ times - and I believe they are <strong>critical while using AI coding tools</strong>.&nbsp;</p><h2>Why Deep Work is so critical</h2><p>Working deeply is the only way to achieve the famous ‘flow’ state - AKA being in the zone.</p><p>More deep work helps engineers to:</p><ul><li data-preset-tag=\"p\"><p>Support their  - they’ll get more work done in less time, so more free time will be left.</p></li><li data-preset-tag=\"p\"><p> - in those focused times the toughest challenges are solved, and the biggest improvements to skills happen.&nbsp;</p></li></ul><p>A big mistake managers make is assuming that with AI coding tools, it’s no longer critical. That engineers need to get used to constantly task switching - as you anyway have to wait for a couple of minutes between prompts, so who cares about distractions.&nbsp;</p><p>What happens then is that the quality of our thoughts and prompts go down. We fall into endless loops of asking the AI to fix the problems, while giving mediocre context.</p><p>If you stay in the flow state, deeper in the problem, you’ll need many less iterations to achieve the same result. No data for this one, only my experience and gut feeling.&nbsp;</p><h2>So what’s the problem with deep work?</h2><p>Remote work should have been an answer to this - no commute, fewer distractions. In reality, only the first part is true.</p><p>Since 2020, in addition to the 13.5% increase in total meetings, there has also been a rise of 60% in remote meetings[5]. The unsurprising part is that 92% of people say they multitask during those meetings[6] - and I would guess the number is just about 100% for software engineers.</p><p>There are 2 main problems with that:</p><h3>1. Work that should be Deep, becomes Shallow</h3><p>Remember the simple test we discussed above? If you can do it in a Zoom meeting =&gt; it’s shallow work.</p><p>A great example is reviewing PRs. If you have a busy day filled with meetings, when would be the best time to review them?</p><p>During the meetings of course… <strong>reviewing a pull request should be deep work! </strong>Same for bug fixes, or writing design documents.</p><p>Doing those tasks during a meeting starts a horrible cycle:</p><ul><li data-preset-tag=\"p\"><p>The quality of the work gets poorer so more problems arise → more meetings are scheduled to address them.</p></li><li data-preset-tag=\"p\"><p>People are being distracted during meetings so no good decisions are taken → more meetings are scheduled…</p></li></ul><p>And it’s not the fault of your multitasking engineers - it’s the fault of your meeting culture.</p><h3><strong>2. Engineers are not reaching the flow state</strong></h3><p>It takes 15 minutes just to get going and only by the 45-minute mark (!) you will hit your peak, when you are fully immersed in the problem.[7]</p><p>Every time you’re distracted, that clock resets thanks to context switching. In a study done by Meta [8], they’ve shown how severe the problem is - engineers get just 2 1-hour sessions a week! (And I find it crazy that a 3 minute session is considered ‘focus time’ at all).&nbsp;</p><img alt=\"\" width=\"189\" height=\"111\" src=\"https://framerusercontent.com/images/CFfo15TqGl24yscXkWqwDiBWis8.png?width=379&amp;height=223\"><p>It was not just the time in meetings that is lost. Every distraction sets you back 15-45 minutes, leaving you by the end of the day with just 1-2 hours of productive time in the BEST case scenario.</p><p>I love this analogy, borrowed from this Reddit comment[9]:</p><img alt=\"No alt text provided for this image\" width=\"406\" height=\"322\" src=\"https://framerusercontent.com/images/NpjBrgUXXz6EUBnRycVW8lAKYQ.png?width=812&amp;height=645\"><p><em>Imagine developers are like miners. digging is our job. Every time you have a meeting, we need to pack our things, and get to the entrance of the mine on time.&nbsp;</em></p><p><em>After the meeting is finished, we need to walk alllll the way back to where we were working, assuming we even remember the right path...</em></p><p><em>So if you want us to get you some diamonds, let us work in peace.</em></p><p>Software engineers need at least 4-5 hours of uninterrupted time a day, and it’s our job as managers to provide it.</p><h2>How can we create deep work time</h2><h3>Improve the meeting culture at your company</h3><p>It’s not that hard to fix - you ‘just’ need to get all the managers to commit to basic rules:</p><ol><li data-preset-tag=\"p\"><p>Meetings should be  - obvious right? But still rare… Have a clear agenda, and clear outcomes.</p></li><li data-preset-tag=\"p\"><p>Have a <strong>fixed daily time for meetings</strong> - and leave big chunks of ‘no-meetings’ time. You can either do no-meeting days, or no-meeting hours, it depends on your organization.&nbsp;</p></li></ol><ol start=\"3\"><li data-preset-tag=\"p\"><p><strong>Invite only people who are really needed</strong> - this is something that remote work is bad at - it has become too easy to just invite everyone. People think to themselves: “Worst case, they’ll multitask, and be available in case they are needed”.This is an awful approach! Remember - you cannot achieve a flow state while multitasking.</p></li></ol><p>But the best way? Get rid of as many meetings as you can!&nbsp;</p><p>In the past 2 years, we’ve studied how hundreds of engineering teams operate. The engineering team at Pylon really impressed us.&nbsp;</p><p>When we asked to see a senior engineer's calendar for the week, it was completely empty. No standups, no sprint planning, no recurring meetings of any kind.</p><p>There's still plenty of collaboration, but it happens instead of recurring meetings. This is probably possible because they're in person 5 days a week, but even in remote settings you for sure can get rid of some meetings.&nbsp;</p><p>And if you can’t get rid of all meetings, we recommend at least having some company-wide blocks of focus time. After analyzing data 600,000+ PRs at Weave, the data shows that most engineers are the most productive at 09:00-11:00 and 14:00-16:00: </p><img alt=\"\" width=\"373\" height=\"282\" src=\"https://framerusercontent.com/images/Wn8CDE710GWIvWoUUVQzENMnww.png?width=746&amp;height=565\" srcset=\"https://framerusercontent.com/images/Wn8CDE710GWIvWoUUVQzENMnww.png?scale-down-to=512&amp;width=746&amp;height=565 512w,https://framerusercontent.com/images/Wn8CDE710GWIvWoUUVQzENMnww.png?width=746&amp;height=565 746w\" data-framer-original-sizes=\"\" sizes=\"(min-width: 1600px) 100vw, (min-width: 1200px) and (max-width: 1599.98px) 100vw, (min-width: 768px) and (max-width: 1199.98px) 100vw, (max-width: 767.98px) 100vw\"><p><em>*Note: Those are just commit times, and we know that probably people work in the hours before that (and that there is a lunch break). Still, our point is that there are 'clusters' of productive times, and you should not fragment your people's workday!</em></p><h3>Rethink your PRs workflow</h3><p>Better yet, do you actually need all those PRs?</p><p>The other thing that surprised us about that team at Pylon is that they have almost no code reviews. Engineers merge their own code and only request reviews if they need input, think they have a risky change, or are still onboarding.</p><p>Code reviews are a big distraction on both sides - when it comes your way you want to do it as fast as possible to not block others, and when the answer comes you are tempted to look at it and address it immediately. In both cases, it can ruin the flow state.</p><p>This goes against conventional wisdom about code quality, but their thought process is simple: if you hire skilled engineers and trust them, there's no reason to bottleneck every change with mandatory reviews.</p><p>Once you get the meetings under control, you can deal with the other interruptions.</p><p>The best way to create a good culture is to cherish your own deep work time, and make sure your team respects it. I have to admit that I’m still struggling with this one - I schedule focus time in my calendar, and put on my headphones, but I still sometimes check Slack and answer when interrupted.</p><p>I know this sets a bad example for my team - deep work time should be sacred, and people should know it’s completely acceptable to not be available in Slack for a couple of hours.</p><h2>Focus time in 2025 becomes critical&nbsp;</h2><p>I believe that the more we start to depend on AI, the more important focus time will become. The models will become much faster with time, and I believe that companies and engineers who learn to enter the flow state  AI will hugely outpace everyone else.</p><p>[1] <a href=\"https://www.notta.ai/en/blog/meeting-statistics\" rel=\"noopener\">https://www.notta.ai/en/blog/meeting-statistics</a></p><p>[2] <a href=\"https://paulgraham.com/makersschedule.html\" rel=\"noopener\">https://paulgraham.com/makersschedule.html</a></p><p>[3] <a href=\"https://www.goodreads.com/book/show/25744928-deep-work\" rel=\"noopener\">https://www.goodreads.com/book/show/25744928-deep-work</a></p><p>[4] <a href=\"https://hbr.org/2014/05/create-a-work-environment-that-fosters-flow\" rel=\"noopener\">https://hbr.org/2014/05/create-a-work-environment-that-fosters-flow</a></p><p>[5] <a href=\"https://www.cfo.com/news/remote-meetings-up-60-since-2020-weekly-stat/654749/\" rel=\"noopener\">https://www.cfo.com/news/remote-meetings-up-60-since-2020-weekly-stat/654749/</a></p><p>[6] <a href=\"https://www.flowtrace.co/collaboration-blog/50-meeting-statistics\" rel=\"noopener\">https://www.flowtrace.co/collaboration-blog/50-meeting-statistics</a></p><p>[7] <a href=\"https://www.locationrebel.com/flow-state/#:~:text=The%20science%20shows%20us%20that,disturb%20you%20until%20after%20lunch\" rel=\"noopener\">https://www.locationrebel.com/flow-state/#:~:text=The%20science%20shows%20us%20that,disturb%20you%20until%20after%20lunch</a>.</p><p>[8] <a href=\"https://users.encs.concordia.ca/~pcr/paper/YChen2022ICSE-industry-preprint.pdf?utm_source=chatgpt.com\" rel=\"noopener\">https://users.encs.concordia.ca/~pcr/paper/YChen2022ICSE-industry-preprint.pdf?utm_source=chatgpt.com</a></p><p>[9] <a href=\"https://www.reddit.com/r/programming/comments/1bbcoec/comment/ku9i16h/\" rel=\"noopener\">https://www.reddit.com/r/programming/comments/1bbcoec/comment/ku9i16h/</a></p>","contentLength":9342,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1nw8fbj/distracting_software_engineers_is_way_more/"},{"title":"Nine HTTP Edge Cases Every API Developer Should Understand","url":"https://blog.dochia.dev/blog/http_edge_cases/","date":1759406871,"author":"/u/ludovicianul","guid":642,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1nw1yhf/nine_http_edge_cases_every_api_developer_should/"},{"title":"The architecture behind 99.9999% uptime in erlang","url":"https://volodymyrpotiichuk.com/blog/articles/the-architecture-behind-99%25-uptime","date":1759397994,"author":"/u/NoBarber9673","guid":643,"unread":true,"content":"<p>\nHey there, have you ever wondered how to build the most stable application in the world? What characteristics does such an application have, and what architecture styles make it possible? It’s pretty impressive how apps like Discord and WhatsApp can handle millions of concurrent users, while some others struggle with just a few thousand. Today, we’ll take a look at how Erlang makes it possible to handle a massive workload while keeping the system alive and stable.</p><p>\nI believe that the best way to describe something complex is to start from the simple things and then gradually move to the complex ones. So let’s start with a simple example.</p><p>\nImagine such a wonderful day:</p><ol><li>\nYou are driving your Porsche Panamera and decide to call your good friend to chat about the upcoming party.  </li><li>\nYour phone sends a signal to the nearest cell tower.  </li><li>\nThe network figures out the best route to reach your friend.  </li><li>\nThe system establishes the connection and rings your friend’s phone.  </li><li>\nOnce your friend picks up, you both start speaking and having a great time.  </li></ol><p>\nEverything works perfectly… until it doesn’t. While you’re driving, your phone switches to a different cell tower, and suddenly the connection drops.</p><p>\nAnd it would be great if your broken call didn’t mess up other calls in the network (John on the other line definitely doesn’t want to deal with your issues, right?). Ideally, you’d just retry the call and keep chatting with your bro about the upcoming party.</p><p>\nIf we turn this situation into a system design lesson, we can pull out a couple of thoughts about reliable systems:</p><ul><li>\nWhat you do shouldn’t hurt others in the system. In other words, things should be isolated so they don’t affect each other.  </li><li>\nWe need mechanisms to monitor and manage those isolated things in a way that lets the system recover from unexpected failures.  </li></ul><p>\nAt first glance, this may seem pretty simple. You can achieve something like this in almost any popular programming language. But the how is very different, and so are the feelings you get while developing and debugging such systems.</p><h3>\nLet’s check what the options</h3><p>\nImagine that we are trying to build a Discord. This is a highload system which handles millions of calls simultaneously. We need to provide the best user experience so people do not leave us and go to Microsoft Teams for example.\nHow would you build such system?</p><p>\nImagine you as a software engineer started working on the system, and you try to handle all calls in one main loop, like this:\n  <img src=\"https://volodymyrpotiichuk.com/images/blog/sync-event-loop.png\" alt=\"Sync event loop\"></p><p>\nAt first look, this seems pretty simple and elegant. However, in reality each call has a connection that needs to be handled. If you put all of them into a single synchronous loop, then while that loop is busy handling one call, all the other calls are forced to wait.</p><p>\nSome systems allow you to create <a href=\"https://www.geeksforgeeks.org/operating-systems/thread-in-operating-system/\">OS threads</a> to handle work in parallel on multiple CPU cores. OS threads are small work units managed by the OS kernel that can run in the background so the main thread of the process isn’t blocked. They are scheduled preemptively, which means the OS can pause one thread and run another at any time, even on a single CPU core.</p><p>\nGreat! You might think, “Let’s give each call its own thread!”\nWhile this seems like a simple way to run things concurrently, there are serious trade-offs:</p><p>\nAll threads in a process share the same memory. When you share the same memory, you can have race conditions when threads trying to work on the same data in parallel:   <img src=\"https://volodymyrpotiichuk.com/images/blog/shared-memory-process.png\" alt=\"Shared memory process\"></p><p>\nTo prevent this, you must use the locks to the data, however it would affect how the threads are waiting for each other:\n  <img src=\"https://volodymyrpotiichuk.com/images/blog/shared-memory-waiting.png\" alt=\"Shared memory waiting\"></p><p>\nSee how threads mostly waiting, not working!</p><p>\nEven if you used the locks, there can be a situation when one of the threads put corrupted data in the shared memory and other threads received shared corrupted data. How would you handle such case?</p><p>\nOS threads are really heavy in terms of memory. Each OS thread takes at least 512 KB just to exist, without doing anything. To compute how many “empty” threads you can have, just divide your RAM by the per-thread memory. It will give you amount of calls that you would have on your machine. If your machine has 8GB of available memory - it would be like 8gb / 512kb = 16,384. Huh, that’s not a millions unfortunately…</p><p>\nWe need to observe the threads: monitor their status, track failures, and react when something goes wrong. With shared state, how would you detect issues in the system, restart only the affected processes (or all if necessary), and ensure everything keeps running smoothly? Pretty complex, right?</p><p>\nWhat if we introduce an event-driven architecture, where your server communicates with other I/O systems via asynchronous events:\n  <img src=\"https://volodymyrpotiichuk.com/images/blog/async-event-loop.png\" alt=\"Async event loop\">\n\nThe event loop won’t be blocked by a single task, allowing you to handle thousands of them on demand, step by step. For CPU-heavy tasks you can use threads, which help prevent blocking the main thread. </p><p>\nThis kind of model already shows us why so many modern languages like Node.JS, Python lean toward event-driven design: it’s efficient and helps avoid bottlenecks. But it also leaves open questions - how do you supervise those tasks? How do you recover from failures? How do you keep track of thousands of concurrent jobs without going crazy? Only after asking those questions it becomes clear why Erlang is interesting.</p><h3>\nHow erlang solves such problems</h3><p>\nErlang is built on top of the BEAM virtual machine. “Virtual” means it runs on top of your operating system and provides abstractions for things like processes, scheduling and message passing.</p><p>\nProcesses in virtual machine operate in isolated memory chunks and communicate with each other via messages (see  <a href=\"https://en.wikipedia.org/wiki/Actor_model\">Actor model</a>). Think of them as people sitting in their own rooms, doing their work and sending emails to communicate (no shared memory). </p><p>\nThe idea behind this design is that each process can fail or succeed independently, and the system can handle millions of them concurrently without affecting the others.</p><p>\nLet’s take a look at the main structure of each process:</p><ol><li>\nStack – keeps track of function calls.  </li><li>\nHeap – stores the process internal data.  </li><li>\nMailbox – a message queue that allows the process to receive messages from other processes.  </li><li>\nPCB (Process Control Block) – metadata about the process, used internally by Erlang.  </li></ol><p>\nSo if you want to spawn a process in the system, you’re really just creating this minimal internal structure that the BEAM needs: its unique identificator, mailbox, stack, heap, and some metadata. It’s lightweight because the process isn’t created by the OS, there is no system call and no need to touch the kernel. Instead, it’s created inside the BEAM virtual machine itself, which takes care of scheduling and managing all these processes.</p><p>\nIn theory, creating an Erlang process takes only 327 words (where word is 4 bytes on 32-bit systems or 8 bytes on 64-bit systems), that’s the raw overhead of its internal structure from the above. Compare that to an OS thread, which usually reserves at least 512 KB (and often up to 8 MB) just for the existence.</p><p>\nIf you can spawn millions of processes, the next question is: how do you keep track of them? Erlang gives you not only cheap isolated processes, but also tools to see, monitor and control them while everything is running. </p><p>\nYou can set up relationships between these lightweight processes and define how they should behave if some of them misbehave. This feature is available as a ready-to-use abstraction in the erlang libraries (a set of generic behaviors), but it’s also something you can build on top of the features available in Erlang and extend on your own. </p><p>\nImagine you’re setting up call connections on your server. Sometimes network errors happen, and you need to restart the connections until they work properly. In Erlang, with linked processes, you can catch a linked process abnormal activity and take the necessary actions yourself - for example, restart it:</p><pre><code></code></pre><p>\nHere we are trying to spawn 10 calls where each can fail with equal probability and if they fail, we want to restart them until they restarted succesfully. Here is a demo:</p><p>\nAnd when you have such a mechanism, you can start building more complex systems on top of it. You can create a supervision tree, where each process monitors another process using built-in behaviors in Erlang (See <a href=\"https://www.erlang.org/doc/apps/stdlib/supervisor\">https://www.erlang.org/doc/apps/stdlib/supervisor</a>). This way, every process is under control — if something goes wrong, that process can be restarted without affecting the whole system. Plus, you always have a clear picture of what’s going on in your system.</p><h3>\nHow does virtual machine schedule millions of processes?</h3><p>\nTo understand how this works, let’s go back to the early days of Erlang. The first two decades of Erlang releases, between 1986 and 2006, it supported using at most one CPU core. This means that only one process could execute at a time on that core. However, they had an ability to execute hundreds of thousands processes very fast without blocking single CPU core with long running tasks. How?</p><p>\nImagine that you have a queue of waiting processes to be executed:</p><ol><li>\nCreate an array of values from 1 to 10000  </li></ol><p>\nIn this case we will take those processes one by one in first-in-first-out order (sorted by the date of the scheduling):</p><ol><li>\nWe will execute first process - it’s pretty simple operation, and we will take only step to complete it.  </li><li>\nWe will execute second process - while we execute it, we see that we make array like , then , then  and so on.\nIn some moment of time, we will understand that this task takes more operations than we would expect to complete it in one batch. In such case, for example on number 5000, we save the current call stack and step where we stop the execution for current process\nand intermidiate data in the process heap, and we move to another process! We don’t want to block our CPU with long running task, so we give the time\nfor other waiting processes.  </li><li>\nWe execute third process - which is also pretty fast.  </li><li>\nWe return to process number 2, in our heap we already have array with values from 1 to 3000, and we continue to process our array until we finish\nit or again we see that this process tooks a many operations to do, we pause it and give other processes their time slice.  </li></ol><p>\nLet’s check this in action with simple demo code, where we simulate the case from above:</p><pre><code></code></pre><p>\nAnd let’s try to execute it:\n  <img src=\"https://volodymyrpotiichuk.com/images/blog/run-concurrently.png\" alt=\"Output\"></p><p>\nAs you see, all the processes get the time for their execution, and they have not blocked each other while executing long running task. I mentioned this technique earlier with OS threads — it’s called preemptive scheduling. It’s used by schedulers in both the BEAM and the OS, where each scheduler runs on a single CPU core and allocates CPU time to every task waiting to be executed.</p><p>\nIn erlang, settings like how many function calls a process can execute before the scheduler switches to another task, along with other configuration, are stored in the Process Control Block I mentioned earlier. You can inspect them using:</p><pre><code></code></pre><p>\nThat’s basically magic behind the concurrent processes on one CPU core. For you, as user of this system, it may looks like you running parallel execution, but in fact, they are running sequentially giving each other space to complete their work. Worth to add, that starting from May 2006, you can run multiple schedulers with multiple CPU cores. It will execute the code truly in parallel between them.</p><h3>\nOne of the features I love the most</h3><p>\nHave you ever thought you could change a part of your application on the fly without redeploying it? Yeah, it’s like changing the tires on a moving car… but safer. And what if I told you that you can debug server processes, functions, and even add new functions to a running system without any downtime? Erlang lets you do that.</p><p>\nTo enable hot code load functionality, Erlang has something called the code server — a process that tracks module states and can keep two versions of the same module in memory. When you load the new version into the memory - processes running the current (old) version will finish their work on that version, while processes started after a new load will run the new version. This way, you can debug and update your system very smoothly without downtime.</p><p>\nAlso, there is a concept of <a href=\"https://www.erlang.org/doc/system/release_handling\"> release upgrades and downgrades </a>. Basically, we can specify a rollout strategy for every release so our code doesn’t need to drop connections at all. It’s a pretty big topic because you need to manually show how to transform the state from the old version to the new version, what to do with processes that are currently running, and so on. However, on my opinion, it’s much simpler to use rolling upgrades with node restarts (which is also provides zero downtime).</p><p>\nIn Erlang, distribution is built right into the system. Just like you can supervise processes, you can also monitor and use other nodes. Nodes can send messages to each other or call functions remotely using RPC (Remote procedure calls), allowing you to coordinate work, handle failures, and scale across machines.</p><p>\nFor example, you can build a cluster of nodes that share the workload via load balancing. If one node goes down, the others can seamlessly take over its tasks. Let’s build a simple load balancer to see how it works.</p><p>\nFirst of all, we will create a load balancer process responsible for getting a random node from the available list and passing it to the caller:</p><pre><code></code></pre><p>\nAfter that, we will start several nodes manually (on the cloud, this could be done automatically on demand) with specific names like these:</p><pre><code></code></pre><p>\nand pass them to our load balancer process as initial argument, so our nodes are aware of each other:\n  <img src=\"https://volodymyrpotiichuk.com/images/blog/start_load_balancer.png\" alt=\"Start load balancer\"></p><p>\nWe see that our erlang nodes are set up correctly and that we’re ready to route our connections. In the next step, we need to create a  module, which will take the node received from the load balancer and perform a remote procedure call on the selected node:</p><pre><code></code></pre><p>\nNow we’re ready to accept connections and observe how the application balances requests across the available nodes:\n  <img src=\"https://volodymyrpotiichuk.com/images/blog/load_balancer_demo.png\" alt=\"Load balancer demo\"></p><p>\nAs you can see, our requests are distributed randomly across the available nodes. If one of them fails, erlang detects it, removes it from the node list, and load balancer routes traffic to the remaining healthy nodes.</p><p>\nThat was a lot of stuff, right? Erlang gives us so many features that in other languages would require special tooling or extra libraries. It makes communication in the system isolated, distributed, reliable, and fault-tolerant, with the ability to debug and even change code at runtime. It’s no miracle that huge, complex systems can achieve 99.999999% uptime when built with Erlang — it’s the architecture itself that allows developers to build such systems quickly and understandably.</p><p>\nI hope you found this article useful, maybe it even inspires you to build your first app on Erlang or Elixir. Don’t forget to subscribe, and see you next time!</p>","contentLength":14947,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1nvzaas/the_architecture_behind_999999_uptime_in_erlang/"}],"tags":["dev","reddit"]}