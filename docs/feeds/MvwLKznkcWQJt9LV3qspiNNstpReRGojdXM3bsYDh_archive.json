{"id":"MvwLKznkcWQJt9LV3qspiNNstpReRGojdXM3bsYDh","title":"Kubernetes Blog","displayTitle":"Dev - Kubernetes Blog","url":"https://kubernetes.io/feed.xml","feedLink":"https://kubernetes.io/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":15,"items":[{"title":"Announcing Changed Block Tracking API support (alpha)","url":"https://kubernetes.io/blog/2025/09/25/csi-changed-block-tracking/","date":1758805200,"author":"","guid":762,"unread":true,"content":"<p>We're excited to announce the alpha support for a  mechanism. This enhances\nthe Kubernetes storage ecosystem by providing an efficient way for\n<a href=\"https://kubernetes.io/docs/concepts/storage/volumes/#csi\">CSI</a> storage drivers to identify changed\nblocks in PersistentVolume snapshots. With a driver that can use the feature, you could benefit\nfrom faster and more resource-efficient backup operations.</p><h2>What is changed block tracking?</h2><p>Changed block tracking enables storage systems to identify and track modifications at the block level\nbetween snapshots, eliminating the need to scan entire volumes during backup operations. The\nimprovement is a change to the Container Storage Interface (CSI), and also to the storage support\nin Kubernetes itself.\nWith the alpha feature enabled, your cluster can:</p><ul><li>Identify allocated blocks within a CSI volume snapshot</li><li>Determine changed blocks between two snapshots of the same volume</li><li>Streamline backup operations by focusing only on changed data blocks</li></ul><p>For Kubernetes users managing large datasets, this API enables significantly more efficient\nbackup processes. Backup applications can now focus only on the blocks that have changed,\nrather than processing entire volumes.</p><div role=\"alert\">As of now, the Changed Block Tracking API is supported only for block volumes and not for\nfile volumes. CSI drivers that manage file-based storage systems will not be able to\nimplement this capability.</div><h2>Benefits of changed block tracking support in Kubernetes</h2><p>As Kubernetes adoption grows for stateful workloads managing critical data, the need for efficient\nbackup solutions becomes increasingly important. Traditional full backup approaches face challenges with:</p><ul><li>: Full volume backups can take hours for large datasets, making it difficult\nto complete within maintenance windows.</li><li><em>High resource utilization</em>: Backup operations consume substantial network bandwidth and I/O\nresources, especially for large data volumes and data-intensive applications.</li><li>: Repetitive full backups store redundant data, causing storage\nrequirements to grow linearly even when only a small percentage of data actually changes between\nbackups.</li></ul><p>The Changed Block Tracking API addresses these challenges by providing native Kubernetes support for\nincremental backup capabilities through the CSI interface.</p><p>The implementation consists of three primary components:</p><ol><li><em>CSI SnapshotMetadata Service API</em>: An API, offered by gRPC, that provides volume\nsnapshot and changed block data.</li><li><em>SnapshotMetadataService API</em>: A Kubernetes CustomResourceDefinition (CRD) that\nadvertises CSI driver metadata service availability and connection details to\ncluster clients.</li><li><em>External Snapshot Metadata Sidecar</em>: An intermediary component that connects CSI\ndrivers to backup applications via a standardized gRPC interface.</li></ol><h2>Implementation requirements</h2><h3>Storage provider responsibilities</h3><p>If you're an author of a storage integration with Kubernetes and want to support the changed block tracking feature, you must implement specific requirements:</p><ol><li><p>: Storage providers need to implement the  service as defined in the <a href=\"https://github.com/container-storage-interface/spec/blob/master/csi.proto\">CSI specifications protobuf</a>. This service requires server-side streaming implementations for the following RPCs:</p><ul><li>: For identifying allocated blocks in a snapshot</li><li>: For determining changed blocks between two snapshots</li></ul></li><li><p><em>Storage backend capabilities</em>: Ensure the storage backend has the capability to track and report block-level changes.</p></li><li><p><em>Deploy external components</em>: Integrate with the <code>external-snapshot-metadata</code> sidecar to expose the snapshot metadata service.</p></li><li><p>: Register the  resource using a CustomResourceDefinition and create a  custom resource that advertises the availability of the metadata service and provides connection details.</p></li><li><p>: Implement proper error handling for these RPCs according to the CSI specification requirements.</p></li></ol><h3>Backup solution responsibilities</h3><p>A backup solution looking to leverage this feature must:</p><ol><li><p>: The backup application must provide a Kubernetes ServiceAccount token when using the\n<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/3314-csi-changed-block-tracking#the-kubernetes-snapshotmetadata-service-api\">Kubernetes SnapshotMetadataService API</a>.\nAppropriate access grants, such as RBAC RoleBindings, must be established to authorize the backup application\nServiceAccount to obtain such tokens.</p></li><li><p><em>Implement streaming client-side code</em>: Develop clients that implement the streaming gRPC APIs defined in the\n<a href=\"https://github.com/kubernetes-csi/external-snapshot-metadata/blob/main/proto/schema.proto\">schema.proto</a> file.\nSpecifically:</p><ul><li>Implement streaming client code for  and  methods</li><li>Handle server-side streaming responses efficiently as the metadata comes in chunks</li><li>Process the  message format with proper error handling</li></ul><p>The <code>external-snapshot-metadata</code> GitHub repository provides a convenient\n<a href=\"https://github.com/kubernetes-csi/external-snapshot-metadata/tree/master/pkg/iterator\">iterator</a>\nsupport package to simplify client implementation.</p></li><li><p><em>Handle large dataset streaming</em>: Design clients to efficiently handle large streams of block metadata that\ncould be returned for volumes with significant changes.</p></li><li><p><em>Optimize backup processes</em>: Modify backup workflows to use the changed block metadata to identify and only\ntransfer changed blocks to make backups more efficient, reducing both backup duration and resource consumption.</p></li></ol><p>To use changed block tracking in your cluster:</p><ol><li>Ensure your CSI driver supports volume snapshots and implements the snapshot metadata capabilities with the required <code>external-snapshot-metadata</code> sidecar</li><li>Make sure the SnapshotMetadataService custom resource is registered using CRD</li><li>Verify the presence of a SnapshotMetadataService custom resource for your CSI driver</li><li>Create clients that can access the API using appropriate authentication (via Kubernetes ServiceAccount tokens)</li></ol><p>The API provides two main functions:</p><ul><li>: Lists blocks allocated in a single snapshot</li><li>: Lists blocks changed between two snapshots</li></ul><p>Depending on feedback and adoption, the Kubernetes developers hope to push the CSI Snapshot Metadata implementation to Beta in the future releases.</p><p>For those interested in trying out this new feature:</p><p>This project, like all of Kubernetes, is the result of hard work by many contributors from diverse backgrounds working together.\nOn behalf of SIG Storage, I would like to offer a huge thank you to the contributors who helped review the design and implementation of the project, including but not limited to the following:</p><p>Thank also to everyone who has contributed to the project, including others who helped review the\n<a href=\"https://github.com/kubernetes/enhancements/pull/4082\">KEP</a> and the\n<a href=\"https://github.com/container-storage-interface/spec/pull/551\">CSI spec PR</a></p><p>For those interested in getting involved with the design and development of CSI or any part of the Kubernetes Storage system,\njoin the <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG).\nWe always welcome new contributors.</p>","contentLength":6358,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Pod Level Resources Graduated to Beta","url":"https://kubernetes.io/blog/2025/09/22/kubernetes-v1-34-pod-level-resources/","date":1758565800,"author":"","guid":761,"unread":true,"content":"<p>On behalf of the Kubernetes community, I am thrilled to announce that the Pod Level Resources feature has graduated to Beta in the Kubernetes v1.34 release and is enabled by default! This significant milestone introduces a new layer of flexibility for defining and managing resource allocation for your Pods. This flexibility stems from the ability to specify CPU and memory resources for the Pod as a whole. Pod level resources can be combined with the container-level specifications to express the exact resource requirements and limits your application needs.</p><h2>Pod-level specification for resources</h2><p>Until recently, resource specifications that applied to Pods were primarily defined\nat the individual container level. While effective, this approach sometimes required\nduplicating or meticulously calculating resource needs across multiple containers\nwithin a single Pod. As a beta feature, Kubernetes allows you to specify the CPU,\nmemory and hugepages resources at the Pod-level. This means you can now define\nresource requests and limits for an entire Pod, enabling easier resource sharing\nwithout requiring granular, per-container management of these resources where\nit's not needed.</p><h2>Why does Pod-level specification matter?</h2><p>This feature enhances resource management in Kubernetes by offering <em>flexible resource management</em> at both the Pod and container levels.</p><ul><li><p>It provides a consolidated approach to resource declaration, reducing the need for\nmeticulous, per-container management, especially for Pods with multiple\ncontainers.</p></li><li><p>Pod-level resources enable containers within a pod to share unused resoures\namongst themselves, promoting efficient utilization within the pod. For example,\nit prevents sidecar containers from becoming performance bottlenecks. Previously,\na sidecar (e.g., a logging agent or service mesh proxy) hitting its individual CPU\nlimit could be throttled and slow down the entire Pod, even if the main\napplication container had plenty of spare CPU. With pod-level resources, the\nsidecar and the main container can share Pod's resource budget, ensuring smooth\noperation during traffic spikes - either the whole Pod is throttled or all\ncontainers work.</p></li><li><p>When both pod-level and container-level resources are specified, pod-level\nrequests and limits take precedence. This gives you – and cluster administrators -\na powerful way to enforce overall resource boundaries for your Pods.</p><p>For scheduling, if a pod-level request is explicitly defined, the scheduler uses\nthat specific value to find a suitable node, insteaf of the aggregated requests of\nthe individual containers. At runtime, the pod-level limit acts as a hard ceiling\nfor the combined resource usage of all containers. Crucially, this pod-level limit\nis the absolute enforcer; even if the sum of the individual container limits is\nhigher, the total resource consumption can never exceed the pod-level limit.</p></li><li><p>Pod-level resources are  in influencing the Quality of Service (QoS) class of the Pod.</p></li><li><p>For Pods running on Linux nodes, the Out-Of-Memory (OOM) score adjustment\ncalculation considers both pod-level and container-level resources requests.</p></li><li><p>Pod-level resources are <strong>designed to be compatible with existing Kubernetes functionalities</strong>, ensuring a smooth integration into your workflows.</p></li></ul><h2>How to specify resources for an entire Pod</h2><p>Using <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature\ngate</a> requires\nKubernetes v1.34 or newer for all cluster components, including the control plane\nand every node. This feature gate is in beta and enabled by default in v1.34.</p><p>You can specify CPU, memory and hugepages resources directly in the Pod spec manifest at the  field for the entire Pod.</p><p>Here’s an example demonstrating a Pod with both CPU and memory requests and limits\ndefined at the Pod level:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>In this example, the  Pod as a whole requests 1 CPU and 100 MiB of memory, and is limited to 1 CPU and 200 MiB of memory. The containers within will operate under these overall Pod-level constraints, as explained in the next section.</p><h3>Interaction with container-level resource requests or limits</h3><p>When both pod-level and container-level resources are specified, <strong>pod-level requests and limits take precedence</strong>. This means the node allocates resources based on the pod-level specifications.</p><p>Consider a Pod with two containers where pod-level CPU and memory requests and\nlimits are defined, and only one container has its own explicit resource\ndefinitions:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><ul><li><p>Pod-Level Limits: The pod-level limits (cpu: \"1\", memory: \"200Mi\") establish an absolute boundary for the entire Pod. The sum of resources consumed by all its containers is enforced at this ceiling and cannot be surpassed.</p></li><li><p>Resource Sharing and Bursting: Containers can dynamically borrow any unused capacity, allowing them to burst as needed, so long as the Pod's aggregate usage stays within the overall limit.</p></li><li><p>Pod-Level Requests: The pod-level requests (cpu: \"1\", memory: \"100Mi\") serve as the foundational resource guarantee for the entire Pod. This value informs the scheduler's placement decision and represents the minimum resources the Pod can rely on during node-level contention.</p></li><li><p>Container-Level Requests: Container-level requests create a priority system within\nthe Pod's guaranteed budget. Because main-app-container has an explicit request\n(cpu: \"0.5\", memory: \"50Mi\"), it is given precedence for its share of resources\nunder resource pressure over the auxiliary-container, which has no\nsuch explicit claim.</p></li></ul><ul><li><p>First of all, <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/#pod-update-and-replacement\">in-place\nresize</a> of pod-level\nresources is  for Kubernetes v1.34 (or earlier). Attempting to\nmodify the  resource limits or requests on a running Pod results in an\nerror: the resize is rejected. The v1.34 implementation of Pod level resources\nfocuses on allowing initial declaration of an overall resource envelope, that\napplies to the . That is distinct from in-place pod resize, which\n(despite what the name might suggest) allows you\nto make dynamic adjustments to  resource\nrequests and limits, within a  Pod,\nand potentially without a container restart. In-place resizing is also not yet a\nstable feature; it graduated to Beta in the v1.33 release.</p></li><li><p>Only CPU, memory, and hugepages resources can be specified at pod-level.</p></li><li><p>Pod-level resources are not supported for Windows pods. If the Pod specification\nexplicitly targets Windows (e.g., by setting spec.os.name: \"windows\"), the API\nserver will reject the Pod during the validation step. If the Pod is not explicitly\nmarked for Windows but is scheduled to a Windows node (e.g., via a nodeSelector),\nthe Kubelet on that Windows node will reject the Pod during its admission process.</p></li><li><p>The Topology Manager, Memory Manager and CPU Manager do not\nalign pods and containers based on pod-level resources as these resource managers\ndon't currently support pod-level resources.</p></li></ul><h4>Getting started and providing feedback</h4><p>Ready to explore  feature? You'll need a Kubernetes cluster running version 1.34 or later. Remember to enable the <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate</a> across your control plane and all nodes.</p><p>As this feature moves through Beta, your feedback is invaluable. Please report any issues or share your experiences via the standard Kubernetes communication channels:</p>","contentLength":7083,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Recovery From Volume Expansion Failure (GA)","url":"https://kubernetes.io/blog/2025/09/19/kubernetes-v1-34-recover-expansion-failure/","date":1758306600,"author":"","guid":760,"unread":true,"content":"<p>Have you ever made a typo when expanding your persistent volumes in Kubernetes? Meant to specify \nbut specified ? This seemingly innocuous problem was kinda hard to fix - and took the project almost 5 years to fix.\n<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#recovering-from-failure-when-expanding-volumes\">Automated recovery from storage expansion</a> has been around for a while in beta; however, with the v1.34 release, we have graduated this to\n.</p><p>While it was always possible to recover from failing volume expansions manually, it usually required cluster-admin access and was tedious to do (See aformentioned link for more information).</p><p>What if you make a mistake and then realize immediately?\nWith Kubernetes v1.34, you should be able to reduce the requested size of the PersistentVolumeClaim (PVC) and, as long as the expansion to previously requested\nsize hadn't finished, you can amend the size requested. Kubernetes will\nautomatically work to correct it. Any quota consumed by failed expansion will be returned to the user and the associated PersistentVolume should be resized to the\nlatest size you specified.</p><p>I'll walk through an example of how all of this works.</p><h2>Reducing PVC size to recover from failed expansion</h2><p>Imagine that you are running out of disk space for one of your database servers, and you want to expand the PVC from previously\nspecified  to  - but you make a typo and specify .</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>Now, you may be out of disk space on your disk array or simply ran out of allocated quota on your cloud-provider. But, assume that expansion to  is never going to succeed.</p><p>In Kubernetes v1.34, you can simply correct your mistake and request a new PVC size,\nthat is smaller than the mistake, provided it is still larger than the original size\nof the actual PersistentVolume.</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>This requires no admin intervention. Even better, any surplus Kubernetes quota that you temporarily consumed will be automatically returned.</p><p>This fault recovery mechanism does have a caveat: whatever new size you specify for the PVC, it  be still higher than the original size in .\nSince Kubernetes doesn't support shrinking your PV objects, you can never go below the size that was originally allocated for your PVC request.</p><h2>Improved error handling and observability of volume expansion</h2><p>Implementing what might look like a relatively minor change also required us to almost\nfully redo how volume expansion works under the hood in Kubernetes.\nThere are new API fields available in PVC objects which you can monitor to observe progress of volume expansion.</p><h3>Improved observability of in-progress expansion</h3><p>You can query <code>.status.allocatedResourceStatus['storage']</code> of a PVC to monitor progress of a volume expansion operation.\nFor a typical block volume, this should transition between <code>ControllerResizeInProgress</code>,  and  and become nil/empty when volume expansion has finished.</p><p>If for some reason, volume expansion to requested size is not feasible it should accordingly be in states like - <code>ControllerResizeInfeasible</code> or .</p><p>You can also observe size towards which Kubernetes is working by watching <code>pvc.status.allocatedResources</code>.</p><h3>Improved error handling and reporting</h3><p>Kubernetes should now retry your failed volume expansions at slower rate, it should make fewer requests to both storage system and Kubernetes apiserver.</p><p>Errors observerd during volume expansion are now reported as condition on PVC objects and should persist unlike events. Kubernetes will now populate  with error keys  or  when volume expansion fails.</p><h3>Fixes long standing bugs in resizing workflows</h3><p>Working on this feature through its lifecycle was challenging and it wouldn't have been possible to reach GA\nwithout feedback from <a href=\"https://github.com/msau42\">@msau42</a>, <a href=\"https://github.com/jsafrane\">@jsafrane</a> and <a href=\"https://github.com/xing-yang\">@xing-yang</a>.</p><p>All of the contributors who worked on this also appreciate the input provided by <a href=\"https://github.com/thockin\">@thockin</a> and <a href=\"https://github.comliggitt\">@liggitt</a> at various Kubernetes contributor summits.</p>","contentLength":3735,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: DRA Consumable Capacity","url":"https://kubernetes.io/blog/2025/09/18/kubernetes-v1-34-dra-consumable-capacity/","date":1758220200,"author":"","guid":759,"unread":true,"content":"<p>Dynamic Resource Allocation (DRA) is a Kubernetes API for managing scarce resources across Pods and containers.\nIt enables flexible resource requests, going beyond simply allocating  number of devices to support more granular usage scenarios.\nWith DRA, users can request specific types of devices based on their attributes, define custom configurations tailored to their workloads, and even share the same resource among multiple containers or Pods.</p><p>In this blog, we focus on the device sharing feature and dive into a new capability introduced in Kubernetes 1.34: ,\nwhich extends DRA to support finer-grained device sharing.</p><h2>Background: device sharing via ResourceClaims</h2><p>From the beginning, DRA introduced the ability for multiple Pods to share a device by referencing the same ResourceClaim.\nThis design decouples resource allocation from specific hardware, allowing for more dynamic and reusable provisioning of devices.</p><p>In Kubernetes 1.33, the new support for  allowed resource drivers to advertise slices of a device that are available, rather than exposing the entire device as an all-or-nothing resource.\nThis enabled Kubernetes to model shareable hardware more accurately.</p><p>But there was still a missing piece: it didn't yet support scenarios\nwhere the device driver manages fine-grained, dynamic portions of a device resource — like network bandwidth — based on user demand,\nor to share those resources independently of ResourceClaims, which are restricted by their spec and namespace.</p><p>That’s where  for DRA comes in.</p><h2>Benefits of DRA consumable capacity support</h2><p>Here's a taste of what you get in a cluster with the <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate</a> enabled.</p><h3>Device sharing across multiple ResourceClaims or DeviceRequests</h3><p>Resource drivers can now support sharing the same device — or even a slice of a device — across multiple ResourceClaims or across multiple DeviceRequests.</p><p>This means that Pods from different namespaces can simultaneously share the same device,\nif permitted and supported by the specific DRA driver.</p><h3>Device resource allocation</h3><p>Kubernetes extends the allocation algorithm in the scheduler to support allocating a portion of a device's resources, as defined in the  field.\nThe scheduler ensures that the total allocated capacity across all consumers never exceeds the device’s total capacity, even when shared across multiple ResourceClaims or DeviceRequests.\nThis is very similar to the way the scheduler allows Pods and containers to share allocatable resources on Nodes;\nin this case, it allows them to share allocatable (consumable) resources on Devices.</p><p>This feature expands support for scenarios where the device driver is able to manage resources  a device and on a per-process basis — for example,\nallocating a specific amount of memory (e.g., 8 GiB) from a virtual GPU,\nor setting bandwidth limits on virtual network interfaces allocated to specific Pods. This aims to provide safe and efficient resource sharing.</p><h3>DistinctAttribute constraint</h3><p>This feature also introduces a new constraint: , which is the complement of the existing  constraint.</p><p>The primary goal of  is to prevent the same underlying device from being allocated multiple times within a single ResourceClaim, which could happen since we are allocating shares (or subsets) of devices.\nThis constraint ensures that each allocation refers to a distinct resource, even if they belong to the same device class.</p><p>It is useful for use cases such as allocating network devices connecting to different subnets to expand coverage or provide redundancy across failure domains.</p><h2>How to use consumable capacity?</h2><p> is introduced as an alpha feature in Kubernetes 1.34. The <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate</a> must be enabled in kubelet, kube-apiserver, kube-scheduler and kube-controller-manager.</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><h3>As a DRA driver developer</h3><p>As a DRA driver developer writing in Golang, you can make a device within a ResourceSlice allocatable to multiple ResourceClaims (or ) by setting  to .</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>Additionally, you can define a policy to restrict how each device's  should be consumed by each  by defining  field in the .\nThe example below shows how to define a policy that requires a GPU with 40 GiB of memory to allocate at least 5 GiB per request, with each allocation in multiples of 5 GiB.</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>This will be published to the ResourceSlice, as partially shown below:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>An allocated device with a specified portion of consumed capacity will have a  field set in the allocation status.</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>This  allows the driver to distinguish between different allocations that refer to the <strong>same device or same statically-partitioned slice</strong> but come from <strong>different  requests</strong>.\nIt acts as a unique identifier for each shared slice, enabling the driver to manage and enforce resource limits independently across multiple consumers.</p><p>As a consumer (or user), the device resource can be requested with a ResourceClaim like this:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>This configuration ensures that the requested device can provide at least 10GiB of .</p><p>Notably that  device that has at least 10GiB of memory can be allocated.\nIf a device that does not support multiple allocations is chosen, the allocation would consume the entire device.\nTo filter only devices that support multiple allocations, you can define a selector like this:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><h2>Integration with DRA device status</h2><p>In device sharing, general device information is provided through the resource slice.\nHowever, some details are set dynamically after allocation.\nThese can be conveyed using the <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/#resourceclaim-device-status\"></a> field of a ResourceClaim.\nThat field is only published in clusters where the <code>DRAResourceClaimDeviceStatus</code>\nfeature gate is enabled.</p><p>If you do have  support available, a driver can expose additional device-specific information beyond the .\nOne particularly useful use case is for virtual networks, where a driver can include the assigned IP address(es) in the status.\nThis is valuable for both network service operations and troubleshooting.</p><ul><li><p> for an example of DRA integration in Kubernetes networking. Try integrating with network resources like , , or smart NICs.</p></li><li><p>Start enabling the  feature gate and experimenting with virtualized or partitionable devices. Specify your workloads with  (for example: fractional bandwidth or memory).</p></li></ul><p>Consumable capacity support enhances the device sharing capability of DRA by allowing effective device sharing across namespaces, across claims, and tailored to each Pod’s actual needs.\nIt also empowers drivers to enforce capacity limits, improves scheduling accuracy, and unlocks new use cases like bandwidth-aware networking and multi-tenant device sharing.</p><p>Try it out, experiment with consumable resources, and help shape the future of dynamic resource allocation in Kubernetes!</p>","contentLength":6593,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Pods Report DRA Resource Health","url":"https://kubernetes.io/blog/2025/09/17/kubernetes-v1-34-pods-report-dra-resource-health/","date":1758133800,"author":"","guid":758,"unread":true,"content":"<p>The rise of AI/ML and other high-performance workloads has made specialized hardware like GPUs, TPUs, and FPGAs a critical component of many Kubernetes clusters. However, as discussed in a <a href=\"https://kubernetes.io/blog/2025/07/03/navigating-failures-in-pods-with-devices/\">previous blog post about navigating failures in Pods with devices</a>, when this hardware fails, it can be difficult to diagnose, leading to significant downtime. With the release of Kubernetes v1.34, we are excited to announce a new alpha feature that brings much-needed visibility into the health of these devices.</p><p>This work extends the functionality of <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/4680-add-resource-health-to-pod-status\">KEP-4680</a>, which first introduced a mechanism for reporting the health of devices managed by Device Plugins. Now, this capability is being extended to <em>Dynamic Resource Allocation (DRA)</em>. Controlled by the  feature gate, this enhancement allows DRA drivers to report device health directly into a Pod's  field, providing crucial insights for operators and developers.</p><h2>Why expose device health in Pod status?</h2><p>For stateful applications or long-running jobs, a device failure can be disruptive and costly. By exposing device health in the  field for a Pod, Kubernetes provides a standardized way for users and automation tools to quickly diagnose issues. If a Pod is failing, you can now check its status to see if an unhealthy device is the root cause, saving valuable time that might otherwise be spent debugging application code.</p><p>This feature introduces a new, optional communication channel between the Kubelet and DRA drivers, built on three core components.</p><h3>A new gRPC health service</h3><p>A new gRPC service, , is defined in the  API group. DRA drivers can implement this service to stream device health updates to the Kubelet. The service includes a  server-streaming RPC that sends the health status (, , or ) for the devices it manages.</p><p>The Kubelet’s  discovers which drivers implement the health service. For each compatible driver, it starts a long-lived  stream to receive health updates. The DRA Manager then consumes these updates and stores them in a persistent  that can survive Kubelet restarts.</p><h3>Populating the Pod status</h3><p>When a device's health changes, the DRA manager identifies all Pods affected by the change and triggers a Pod status update. A new field, , is now part of the  API object. The Kubelet populates this field with the current health of each device allocated to the container.</p><p>If a Pod is in a  state, you can use <code>kubectl describe pod &lt;pod-name&gt;</code> to inspect its status. If an allocated device has failed, the output will now include the  field, clearly indicating the problem:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>This explicit status makes it clear that the issue is with the underlying hardware, not the application.</p><p>Now you can improve the failure detection logic to react on the unhealthy devices associated with the Pod by de-scheduling a Pod.</p><p>As this is an alpha feature in Kubernetes v1.34, you must take the following steps to use it:</p><ol><li>Enable the  feature gate on your kube-apiserver and kubelets.</li><li>Ensure you are using a DRA driver that implements the <code>v1alpha1 DRAResourceHealth</code> gRPC service.</li></ol><p>If you are developing a DRA driver, make sure to think about device failure detection strategy and ensure that your driver is integrated with this feature. This way, your driver will improve the user experience and simplify debuggability of hardware issues.</p><p>This is the first step in a broader effort to improve how Kubernetes handles device failures. As we gather feedback on this alpha feature, the community is planning several key enhancements before graduating to Beta:</p><ul><li><em>Detailed health messages:</em> To improve the troubleshooting experience, we plan to add a human-readable message field to the gRPC API. This will allow DRA drivers to provide specific context for a health status, such as \"GPU temperature exceeds threshold\" or \"NVLink connection lost\".</li><li><em>Configurable health timeouts:</em> The timeout for marking a device's health as \"Unknown\" is currently hardcoded. We plan to make this configurable, likely on a per-driver basis, to better accommodate the different health-reporting characteristics of various hardware.</li><li><em>Improved post-mortem troubleshooting:</em> We will address a known limitation where health updates may not be applied to pods that have already terminated. This fix will ensure that the health status of a device at the time of failure is preserved, which is crucial for troubleshooting batch jobs and other \"run-to-completion\" workloads.</li></ul><p>This feature was developed as part of <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/4680-add-resource-health-to-pod-status\">KEP-4680</a>, and community feedback is crucial as we work toward graduating it to Beta. We have more improvements of device failure handling in k8s and encourage you to try it out and share your experiences with the SIG Node community!</p>","contentLength":4631,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Moving Volume Group Snapshots to v1beta2","url":"https://kubernetes.io/blog/2025/09/16/kubernetes-v1-34-volume-group-snapshot-beta-2/","date":1758047400,"author":"","guid":757,"unread":true,"content":"<p>Volume group snapshots were <a href=\"https://kubernetes.io/blog/2023/05/08/kubernetes-1-27-volume-group-snapshot-alpha/\">introduced</a>\nas an Alpha feature with the Kubernetes 1.27 release and moved to <a href=\"https://kubernetes.io/blog/2024/12/18/kubernetes-1-32-volume-group-snapshot-beta/\">Beta</a> in the Kubernetes 1.32 release.\nThe recent release of Kubernetes v1.34 moved that support to a second beta.\nThe support for volume group snapshots relies on a set of\n<a href=\"https://kubernetes-csi.github.io/docs/group-snapshot-restore-feature.html#volume-group-snapshot-apis\">extension APIs for group snapshots</a>.\nThese APIs allow users to take crash consistent snapshots for a set of volumes.\nBehind the scenes, Kubernetes uses a label selector to group multiple PersistentVolumeClaims\nfor snapshotting.\nA key aim is to allow you restore that set of snapshots to new volumes and\nrecover your workload based on a crash consistent recovery point.</p><p>This new feature is only supported for <a href=\"https://kubernetes-csi.github.io/docs/\">CSI</a> volume drivers.</p><p>While testing the beta version, we encountered an <a href=\"https://github.com/kubernetes-csi/external-snapshotter/issues/1271\">issue</a> where the  field is not set for individual VolumeSnapshotContents and VolumeSnapshots if CSI driver does not implement the ListSnapshots RPC call.\nWe evaluated various options <a href=\"https://docs.google.com/document/d/1LLBSHcnlLTaP6ZKjugtSGQHH2LGZPndyfnNqR1YvzS4/edit?tab=t.0\">here</a> and decided to make this change releasing a new beta for the API.</p><p>Specifically, a VolumeSnapshotInfo struct is added in v1beta2, it contains information for an individual volume snapshot that is a member of a volume group snapshot.\nVolumeSnapshotInfoList, a list of VolumeSnapshotInfo, is added to VolumeGroupSnapshotContentStatus, replacing VolumeSnapshotHandlePairList.\nVolumeSnapshotInfoList is a list of snapshot information returned by the CSI driver to identify snapshots on the storage system.\nVolumeSnapshotInfoList is populated by the csi-snapshotter sidecar based on the CSI CreateVolumeGroupSnapshotResponse returned by the CSI driver's CreateVolumeGroupSnapshot call.</p><p>The existing v1beta1 API objects will be converted to the new v1beta2 API objects by a conversion webhook.</p><p>Depending on feedback and adoption, the Kubernetes project plans to push the volume\ngroup snapshot implementation to general availability (GA) in a future release.</p><p>This project, like all of Kubernetes, is the result of hard work by many contributors\nfrom diverse backgrounds working together. On behalf of SIG Storage, I would like to\noffer a huge thank you to the contributors who stepped up these last few quarters\nto help the project reach beta:</p><p>For those interested in getting involved with the design and development of CSI or\nany part of the Kubernetes Storage system, join the\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG).\nWe always welcome new contributors.</p>","contentLength":2388,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Decoupled Taint Manager Is Now Stable","url":"https://kubernetes.io/blog/2025/09/15/kubernetes-v1-34-decoupled-taint-manager-is-now-stable/","date":1757961000,"author":"","guid":756,"unread":true,"content":"<p>This enhancement separates the responsibility of managing node lifecycle and pod eviction into two distinct components.\nPreviously, the node lifecycle controller handled both marking nodes as unhealthy with NoExecute taints and evicting pods from them.\nNow, a dedicated taint eviction controller manages the eviction process, while the node lifecycle controller focuses solely on applying taints.\nThis separation not only improves code organization but also makes it easier to improve taint eviction controller or build custom implementations of the taint based eviction.</p><p>The feature gate <code>SeparateTaintEvictionController</code> has been promoted to GA in this release.\nUsers can optionally disable taint-based eviction by setting <code>--controllers=-taint-eviction-controller</code>\nin kube-controller-manager.</p><p>We offer a huge thank you to all the contributors who helped with design,\nimplementation, and review of this feature and helped move it from beta to stable:</p><ul><li>Yuan Chen (@yuanchen8911)</li><li>Aldo Culquicondor (@alculquicondor)</li><li>Sergey Kanzhelev (@SergeyKanzhelev)</li><li>Wojciech Tyczynski (@wojtek-t)</li></ul>","contentLength":1071,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Autoconfiguration for Node Cgroup Driver Goes GA","url":"https://kubernetes.io/blog/2025/09/12/kubernetes-v1-34-cri-cgroup-driver-lookup-now-ga/","date":1757701800,"author":"","guid":755,"unread":true,"content":"<p>Historically, configuring the correct cgroup driver has been a pain point for users running new\nKubernetes clusters. On Linux systems, there are two different cgroup drivers:\n and . In the past, both the <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/\">kubelet</a>\nand CRI implementation (like CRI-O or containerd) needed to be configured to use\nthe same cgroup driver, or else the kubelet would misbehave without any explicit\nerror message. This was a source of headaches for many cluster admins. Now, we've\n(almost) arrived at the end of that headache.</p><h2>Automated cgroup driver detection</h2><p>In v1.28.0, the SIG Node community introduced the feature gate\n<code>KubeletCgroupDriverFromCRI</code>, which instructs the kubelet to ask the CRI\nimplementation which cgroup driver to use. You can read more <a href=\"https://kubernetes.io/blog/2024/08/21/cri-cgroup-driver-lookup-now-beta/\">here</a>.\nAfter many releases of waiting for each CRI implementation to have major versions released\nand packaged in major operating systems, this feature has gone GA as of Kubernetes 1.34.0.</p><p>In addition to setting the feature gate, a cluster admin needs to ensure their\nCRI implementation is new enough:</p><ul><li>containerd: Support was added in v2.0.0</li><li>CRI-O: Support was added in v1.28.0</li></ul><h2>Announcement: Kubernetes is deprecating containerd v1.y support</h2><p>While CRI-O releases versions that match Kubernetes versions, and thus CRI-O\nversions without this behavior are no longer supported, containerd maintains its\nown release cycle. containerd support for this feature is only in v2.0 and\nlater, but Kubernetes 1.34 still supports containerd 1.7 and other LTS releases\nof containerd.</p><p>The Kubernetes SIG Node community has formally agreed upon a final support\ntimeline for containerd v1.y. The last Kubernetes release to offer this support\nwill be the last released version of v1.35, and support will be dropped in\nv1.36.0. To assist administrators in managing this future transition,\na new detection mechanism is available. You are able to monitor\nthe <code>kubelet_cri_losing_support</code> metric to determine if any nodes in your cluster\nare using a containerd version that will soon be outdated. The presence of\nthis metric with a version label of  will indicate that the node's containerd\nruntime is not new enough for the upcoming requirements. Consequently, an\nadministrator will need to upgrade containerd to v2.0 or a later version before,\nor at the same time as, upgrading the kubelet to v1.36.0.</p>","contentLength":2301,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Mutable CSI Node Allocatable Graduates to Beta","url":"https://kubernetes.io/blog/2025/09/11/kubernetes-v1-34-mutable-csi-node-allocatable-count/","date":1757615400,"author":"","guid":754,"unread":true,"content":"<p>Traditionally, Kubernetes <a href=\"https://kubernetes-csi.github.io/docs/introduction.html\">CSI drivers</a> report a static maximum volume attachment limit when initializing. However, actual attachment capacities can change during a node's lifecycle for various reasons, such as:</p><ul><li>Manual or external operations attaching/detaching volumes outside of Kubernetes control.</li><li>Dynamically attached network interfaces or specialized hardware (GPUs, NICs, etc.) consuming available slots.</li><li>Multi-driver scenarios, where one CSI driver’s operations affect available capacity reported by another.</li></ul><p>Static reporting can cause Kubernetes to schedule pods onto nodes that appear to have capacity but don't, leading to pods stuck in a  state.</p><h2>Dynamically adapting CSI volume limits</h2><p>With this new feature, Kubernetes enables CSI drivers to dynamically adjust and report node attachment capacities at runtime. This ensures that the scheduler, as well as other components relying on this information, have the most accurate, up-to-date view of node capacity.</p><p>Kubernetes supports two mechanisms for updating the reported node volume limits:</p><ul><li> CSI drivers specify an interval to periodically refresh the node's allocatable capacity.</li><li> An immediate update triggered when a volume attachment fails due to exhausted resources ( error).</li></ul><p>To use this beta feature, the <code>MutableCSINodeAllocatableCount</code> feature gate must be enabled in these components:</p><h3>Example CSI driver configuration</h3><p>Below is an example of configuring a CSI driver to enable periodic updates every 60 seconds:</p><pre tabindex=\"0\"><code>apiVersion: storage.k8s.io/v1\nkind: CSIDriver\nmetadata:\nname: example.csi.k8s.io\nspec:\nnodeAllocatableUpdatePeriodSeconds: 60\n</code></pre><p>This configuration directs kubelet to periodically call the CSI driver's  method every 60 seconds, updating the node’s allocatable volume count. Kubernetes enforces a minimum update interval of 10 seconds to balance accuracy and resource usage.</p><p>When a volume attachment operation fails due to a  error (gRPC code ), Kubernetes immediately updates the allocatable count instead of waiting for the next periodic update. The Kubelet then marks the affected pods as Failed, enabling their controllers to recreate them. This prevents pods from getting permanently stuck in the  state.</p><p>To enable this feature in your Kubernetes v1.34 cluster:</p><ol><li>Enable the feature gate <code>MutableCSINodeAllocatableCount</code> on the  and  components.</li><li>Update your CSI driver configuration by setting <code>nodeAllocatableUpdatePeriodSeconds</code>.</li><li>Monitor and observe improvements in scheduling accuracy and pod placement reliability.</li></ol><p>This feature is currently in beta and the Kubernetes community welcomes your feedback. Test it, share your experiences, and help guide its evolution to GA stability.</p>","contentLength":2639,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Use An Init Container To Define App Environment Variables","url":"https://kubernetes.io/blog/2025/09/10/kubernetes-v1-34-env-files/","date":1757529000,"author":"","guid":753,"unread":true,"content":"<p>Kubernetes typically uses ConfigMaps and Secrets to set environment variables,\nwhich introduces additional API calls and complexity,\nFor example, you need to separately manage the Pods of your workloads\nand their configurations, while ensuring orderly\nupdates for both the configurations and the workload Pods.</p><p>Alternatively, you might be using a vendor-supplied container\nthat requires environment variables (such as a license key or a one-time token),\nbut you don’t want to hard-code them or mount volumes just to get the job done.</p><p>If that's the situation you are in, you now have a new (alpha) way to\nachieve that. Provided you have the <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate</a>\nenabled across your cluster, you can tell the kubelet to load a container's\nenvironment variables from a volume (the volume must be part of the Pod that\nthe container belongs to).\nthis feature gate allows you to load environment variables directly from a file in an emptyDir volume\nwithout actually mounting that file into the container.\nIt’s a simple yet elegant solution to some surprisingly common problems.</p><p>At its core, this feature allows you to point your container to a file,\none generated by an ,\nand have Kubernetes parse that file to set your environment variables.\nThe file lives in an  volume (a temporary storage space that lasts as long as the pod does),\nYour main container doesn’t need to mount the volume.\nThe kubelet will read the file and inject these variables when the container starts.</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>Using this approach is a breeze.\nYou define your environment variables in the pod spec using the  field,\nwhich tells Kubernetes where to find the file and which key to pull.\nThe file itself resembles the standard for .env syntax (think KEY=VALUE),\nand (for this alpha stage at least) you must ensure that it is written into\nan  volume. Other volume types aren't supported for this feature.\nAt least one init container must mount that  volume (to write the file),\nbut the main container doesn’t need to—it just gets the variables handed to it at startup.</p><p>While this feature supports handling sensitive data such as keys or tokens,\nnote that its implementation relies on  volumes mounted into pod.\nOperators with node filesystem access could therefore\neasily retrieve this sensitive data through pod directory paths.</p><p>If storing sensitive data like keys or tokens using this feature,\nensure your cluster security policies effectively protect nodes\nagainst unauthorized access to prevent exposure of confidential information.</p><p>This feature will eliminate a number of complex workarounds used today, simplifying\napps authoring, and opening doors for more use cases. Kubernetes stays flexible and\nopen for feedback. Tell us how you use this feature or what is missing.</p>","contentLength":2725,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Snapshottable API server cache","url":"https://kubernetes.io/blog/2025/09/09/kubernetes-v1-34-snapshottable-api-server-cache/","date":1757442600,"author":"","guid":752,"unread":true,"content":"<p>For years, the Kubernetes community has been on a mission to improve the stability and performance predictability of the API server.\nA major focus of this effort has been taming  requests, which have historically been a primary source of high memory usage and heavy load on the  datastore.\nWith each release, we've chipped away at the problem, and today, we're thrilled to announce the final major piece of this puzzle.</p><p>The <em>snapshottable API server cache</em> feature has graduated to  in Kubernetes v1.34,\nculminating a multi-release effort to allow virtually all read requests to be served directly from the API server's cache.</p><p>The path to the current state involved several key enhancements over recent releases that paved the way for today's announcement.</p><h3>Consistent reads from cache (Beta in v1.31)</h3><p>While the API server has long used a cache for performance, a key milestone was guaranteeing <em>consistent reads of the latest data</em> from it. This v1.31 enhancement allowed the watch cache to be used for strongly-consistent read requests for the first time, a huge win as it enabled  (e.g. \"a list of pods bound to this node\") to be safely served from the cache instead of etcd, dramatically reducing its load for common workloads.</p><h3>Taming large responses with streaming (Beta in v1.33)</h3><p>Another key improvement was tackling the problem of memory spikes when transmitting large responses. The streaming encoder, introduced in v1.33, allowed the API server to send list items one by one, rather than buffering the entire multi-gigabyte response in memory. This made the memory cost of sending a response predictable and minimal, regardless of its size.</p><p>Despite these huge improvements, a critical gap remained. Any request for a historical —most commonly used for paginating through large result sets—still had to bypass the cache and query  directly. This meant that the cost of  the data was still unpredictable and could put significant memory pressure on the API server.</p><p>The <em>snapshottable API server cache</em> solves this final piece of the puzzle.\nThis feature enhances the watch cache, enabling it to generate efficient, point-in-time snapshots of its state.</p><p>Here’s how it works: for each update, the cache creates a lightweight snapshot.\nThese snapshots are \"lazy copies,\" meaning they don't duplicate objects but simply store pointers, making them incredibly memory-efficient.</p><p>When a  request for a historical  arrives, the API server now finds the corresponding snapshot and serves the response directly from its memory.\nThis closes the final major gap, allowing paginated requests to be served entirely from the cache.</p><p>With this final piece in place, the synergy of these three features ushers in a new era of API server predictability and performance:</p><ol><li>:  and  work together to ensure nearly all read requests—whether for the latest data or a historical snapshot—are served from the API server's memory.</li><li>:  ensure that sending this data to the client has a minimal and constant memory footprint.</li></ol><p>The result is a system where the resource cost of read operations is almost fully predictable and much more resiliant to spikes in request load.\nThis means dramatically reduced memory pressure, a lighter load on , and a more stable, scalable, and reliable control plane for all Kubernetes clusters.</p><p>With its graduation to Beta, the  feature gate is  in Kubernetes v1.34. There are no actions required to start benefiting from these performance and stability improvements.</p><p>Special thanks for designing, implementing, and reviewing these critical features go to:</p><p>...and many others in SIG API Machinery. This milestone is a testament to the community's dedication to building a more scalable and robust Kubernetes.</p>","contentLength":3699,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: VolumeAttributesClass for Volume Modification GA","url":"https://kubernetes.io/blog/2025/09/08/kubernetes-v1-34-volume-attributes-class/","date":1757356200,"author":"","guid":751,"unread":true,"content":"<p>The VolumeAttributesClass API, which empowers users to dynamically modify volume attributes, has officially graduated to General Availability (GA) in Kubernetes v1.34. This marks a significant milestone, providing a robust and stable way to tune your persistent storage directly within Kubernetes.</p><h2>What is VolumeAttributesClass?</h2><p>At its core, VolumeAttributesClass is a cluster-scoped resource that defines a set of mutable parameters for a volume. Think of it as a \"profile\" for your storage, allowing cluster administrators to expose different quality-of-service (QoS) levels or performance tiers.</p><p>Users can then specify a <code>volumeAttributesClassName</code> in their PersistentVolumeClaim (PVC) to indicate which class of attributes they desire. The magic happens through the Container Storage Interface (CSI): when a PVC referencing a VolumeAttributesClass is updated, the associated CSI driver interacts with the underlying storage system to apply the specified changes to the volume.</p><ul><li>Dynamically scale performance: Increase IOPS or throughput for a busy database, or reduce it for a less critical application.</li><li>Optimize costs: Adjust attributes on the fly to match your current needs, avoiding over-provisioning.</li><li>Simplify operations: Manage volume modifications directly within the Kubernetes API, rather than relying on external tools or manual processes.</li></ul><h2>What is new from Beta to GA</h2><p>There are two major enhancements from beta.</p><h3>Cancellation support when errors occur</h3><p>To improve resilience and user experience, the GA release introduces explicit cancel support when a requested volume modification encounters an error. If the underlying storage system or CSI driver indicates that the requested changes cannot be applied (e.g., due to invalid arguments), users can cancel the operation and revert the volume to its previous stable configuration, preventing the volume from being left in an inconsistent state.</p><h3>Quota support based on scope</h3><p>While VolumeAttributesClass doesn't add a new quota type, the Kubernetes control plane can be configured to enforce quotas on PersistentVolumeClaims that reference a specific VolumeAttributesClass.</p><p>This is achieved by using the  field in a ResourceQuota to target PVCs that have <code>.spec.volumeAttributesClassName</code> set to a particular VolumeAttributesClass name. Please see more details <a href=\"https://kubernetes.io/docs/concepts/policy/resource-quotas/#resource-quota-per-volumeattributesclass\">here</a>.</p><h2>Drivers support VolumeAttributesClass</h2><ul><li>Amazon EBS CSI Driver: The AWS EBS CSI driver has robust support for VolumeAttributesClass and allows you to modify parameters like volume type (e.g., gp2 to gp3, io1 to io2), IOPS, and throughput of EBS volumes dynamically.</li><li>Google Compute Engine (GCE) Persistent Disk CSI Driver (pd.csi.storage.gke.io): This driver also supports dynamic modification of persistent disk attributes, including IOPS and throughput, via VolumeAttributesClass.</li></ul><p>For any inquiries or specific questions related to VolumeAttributesClass, please reach out to the <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">SIG Storage community</a>.</p>","contentLength":2904,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Pod Replacement Policy for Jobs Goes GA","url":"https://kubernetes.io/blog/2025/09/05/kubernetes-v1-34-pod-replacement-policy-for-jobs-goes-ga/","date":1757097000,"author":"","guid":750,"unread":true,"content":"<p>In Kubernetes v1.34, the  feature has reached general availability (GA).\nThis blog post describes the Pod replacement policy feature and how to use it in your Jobs.</p><h2>About Pod Replacement Policy</h2><p>By default, the Job controller immediately recreates Pods as soon as they fail or begin terminating (when they have a deletion timestamp).</p><p>As a result, while some Pods are terminating, the total number of running Pods for a Job can temporarily exceed the specified parallelism.\nFor Indexed Jobs, this can even mean multiple Pods running for the same index at the same time.</p><p>This behavior works fine for many workloads, but it can cause problems in certain cases.</p><p>For example, popular machine learning frameworks like TensorFlow and\n<a href=\"https://jax.readthedocs.io/en/latest/\">JAX</a> expect exactly one Pod per worker index.\nIf two Pods run at the same time, you might encounter errors such as:</p><pre tabindex=\"0\"><code>/job:worker/task:4: Duplicate task registration with task_name=/job:worker/replica:0/task:4\n</code></pre><p>Additionally, starting replacement Pods before the old ones fully terminate can lead to:</p><ul><li>Scheduling delays by kube-scheduler as the nodes remain occupied.</li><li>Unnecessary cluster scale-ups to accommodate the replacement Pods.</li><li>Temporary bypassing of quota checks by workload orchestrators like <a href=\"https://kueue.sigs.k8s.io/\">Kueue</a>.</li></ul><p>With Pod replacement policy, Kubernetes gives you control over when the control plane\nreplaces terminating Pods, helping you avoid these issues.</p><h2>How Pod Replacement Policy works</h2><p>This enhancement means that Jobs in Kubernetes have an optional field <code>.spec.podReplacementPolicy</code>.\nYou can choose one of two policies:</p><ul><li> (default): Replaces Pods as soon as they start terminating.</li><li>: Replaces Pods only after they fully terminate and transition to the  phase.</li></ul><p>Setting the policy to  ensures that a new Pod is only created after the previous one has completely terminated.</p><p>For Jobs with a Pod Failure Policy, the default  is , and no other value is allowed.\nSee <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/#pod-failure-policy\">Pod Failure Policy</a> to learn more about Pod Failure Policies for Jobs.</p><p>You can check how many Pods are currently terminating by inspecting the Job’s  field:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>Here’s a Job example that executes a task two times () in parallel () and\nreplaces Pods only after they fully terminate (<code>spec.podReplacementPolicy: Failed</code>):</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>If a Pod receives a SIGTERM signal (deletion, eviction, preemption...), it begins terminating.\nWhen the container handles termination gracefully, cleanup may take some time.</p><p>When the Job starts, we will see two Pods running:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>Let's delete one of the Pods ().</p><p>With the  policy, as soon as one Pod () starts terminating, the Job controller immediately creates a new Pod () to replace it.</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>With the  policy, the new Pod () is not created while the old Pod () is terminating.</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>When the terminating Pod has fully transitioned to the  phase, a new Pod is created:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>As with any Kubernetes feature, multiple people contributed to getting this\ndone, from testing and filing bugs to reviewing code.</p><p>As this feature moves to stable after 2 years, we would like to thank the following people:</p><p>If you are interested in working on new features in the space we recommend\nsubscribing to our <a href=\"https://kubernetes.slack.com/messages/wg-batch\">Slack</a>\nchannel and attending the regular community meetings.</p>","contentLength":3101,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: PSI Metrics for Kubernetes Graduates to Beta","url":"https://kubernetes.io/blog/2025/09/04/kubernetes-v1-34-introducing-psi-metrics-beta/","date":1757010600,"author":"","guid":749,"unread":true,"content":"<p>As Kubernetes clusters grow in size and complexity, understanding the health and performance of individual nodes becomes increasingly critical. We are excited to announce that as of Kubernetes v1.34, <strong>Pressure Stall Information (PSI) Metrics</strong> has graduated to Beta.</p><p><a href=\"https://docs.kernel.org/accounting/psi.html\">Pressure Stall Information (PSI)</a> is a feature of the Linux kernel (version 4.20 and later)\nthat provides a canonical way to quantify pressure on infrastructure resources,\nin terms of whether demand for a resource exceeds current supply.\nIt moves beyond simple resource utilization metrics and instead\nmeasures the amount of time that tasks are stalled due to resource contention.\nThis is a powerful way to identify and diagnose resource bottlenecks that can impact application performance.</p><p>PSI exposes metrics for CPU, memory, and I/O, categorized as either  or  pressure:</p><dl><dd>The percentage of time that  task is stalled on a resource. This indicates some level of resource contention.</dd><dd>The percentage of time that  non-idle tasks are stalled on a resource simultaneously. This indicates a more severe resource bottleneck.</dd></dl><p>These metrics are aggregated over 10-second, 1-minute, and 5-minute rolling windows, providing a comprehensive view of resource pressure over time.</p><h2>PSI metrics in Kubernetes</h2><p>With the  feature gate enabled, the kubelet can now collect PSI metrics from the Linux kernel and expose them through two channels: the <a href=\"https://kubernetes.io/docs/reference/instrumentation/node-metrics/#summary-api-source\">Summary API</a> and the  Prometheus endpoint. This allows you to monitor and alert on resource pressure at the node, pod, and container level.</p><p>The following new metrics are available in Prometheus exposition format via :</p><ul><li><code>container_pressure_cpu_stalled_seconds_total</code></li><li><code>container_pressure_cpu_waiting_seconds_total</code></li><li><code>container_pressure_memory_stalled_seconds_total</code></li><li><code>container_pressure_memory_waiting_seconds_total</code></li><li><code>container_pressure_io_stalled_seconds_total</code></li><li><code>container_pressure_io_waiting_seconds_total</code></li></ul><p>These metrics, along with the data from the Summary API, provide a granular view of resource pressure, enabling you to pinpoint the source of performance issues and take corrective action. For example, you can use these metrics to:</p><ul><li> A steadily increasing  pressure for memory can indicate a memory leak in an application.</li><li><strong>Optimize resource requests and limits:</strong> By understanding the resource pressure of your workloads, you can more accurately tune their resource requests and limits.</li><li> You can use PSI metrics to trigger autoscaling events, ensuring that your workloads have the resources they need to perform optimally.</li></ul><h2>How to enable PSI metrics</h2><p>To enable PSI metrics in your Kubernetes cluster, you need to:</p><ol><li><strong>Ensure your nodes are running a Linux kernel version 4.20 or later and are using cgroup v2.</strong></li><li><strong>Enable the  feature gate on the kubelet.</strong></li></ol><p>Once enabled, you can start scraping the  endpoint with your Prometheus-compatible monitoring solution or query the Summary API to collect and visualize the new PSI metrics. Note that PSI is a Linux-kernel feature, so these metrics are not available on Windows nodes. Your cluster can contain a mix of Linux and Windows nodes, and on the Windows nodes the kubelet does not expose PSI metrics.</p><p>We are excited to bring PSI metrics to the Kubernetes community and look forward to your feedback. As a beta feature, we are actively working on improving and extending this functionality towards a stable GA release. We encourage you to try it out and share your experiences with us.</p>","contentLength":3378,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34: Service Account Token Integration for Image Pulls Graduates to Beta","url":"https://kubernetes.io/blog/2025/09/03/kubernetes-v1-34-sa-tokens-image-pulls-beta/","date":1756924200,"author":"","guid":748,"unread":true,"content":"<p>The Kubernetes community continues to advance security best practices\nby reducing reliance on long-lived credentials.\nFollowing the successful <a href=\"https://kubernetes.io/blog/2025/05/07/kubernetes-v1-33-wi-for-image-pulls/\">alpha release in Kubernetes v1.33</a>,\n<em>Service Account Token Integration for Kubelet Credential Providers</em>\nhas now graduated to  in Kubernetes v1.34,\nbringing us closer to eliminating long-lived image pull secrets from Kubernetes clusters.</p><p>This enhancement allows credential providers\nto use workload-specific service account tokens to obtain registry credentials,\nproviding a secure, ephemeral alternative to traditional image pull secrets.</p><p>The beta graduation brings several important changes\nthat make the feature more robust and production-ready:</p><p><strong>Breaking change from alpha</strong>: The  field is \nin the credential provider configuration when using service account tokens.\nThis field is new in beta and must be specified to ensure proper caching behavior.</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>Choose between two caching strategies:</p><ul><li>: Cache credentials per service account token\n(use when credential lifetime is tied to the token).\nThis is useful when the credential provider transforms the service account token into registry credentials\nwith the same lifetime as the token, or when registries support Kubernetes service account tokens directly.\nNote: The kubelet cannot send service account tokens directly to registries;\ncredential provider plugins are needed to transform tokens into the username/password format expected by registries.</li><li>: Cache credentials per service account identity\n(use when credentials are valid for all pods using the same service account)</li></ul><h3>Isolated image pull credentials</h3><p>The beta release provides stronger security isolation for container images\nwhen using service account tokens for image pulls.\nIt ensures that pods can only access images that were pulled using ServiceAccounts they're authorized to use.\nThis prevents unauthorized access to sensitive container images\nand enables granular access control where different workloads can have different registry permissions\nbased on their ServiceAccount.</p><p>When credential providers use service account tokens,\nthe system tracks ServiceAccount identity (namespace, name, and <a href=\"https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#uids\">UID</a>) for each pulled image.\nWhen a pod attempts to use a cached image,\nthe system verifies that the pod's ServiceAccount matches exactly with the ServiceAccount\nthat was used to originally pull the image.</p><p>Administrators can revoke access to previously pulled images\nby deleting and recreating the ServiceAccount,\nwhich changes the UID and invalidates cached image access.</p><p>Credential providers opt into using ServiceAccount tokens\nby configuring the  field:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>At a high level,  coordinates with your credential provider\nand the container runtime as follows:</p><ul><li><p>When the image is not present locally:</p><ul><li> checks its credential cache using the configured \n( or )</li><li>If needed,  requests a ServiceAccount token for the pod's ServiceAccount\nand passes it, plus any required annotations, to the credential provider</li><li>The provider exchanges that token for registry credentials\nand returns them to </li><li> caches credentials per the  strategy\nand pulls the image with those credentials</li><li> records the ServiceAccount coordinates (namespace, name, UID)\nassociated with the pulled image for later authorization checks</li></ul></li><li><p>When the image is already present locally:</p><ul><li> verifies the pod's ServiceAccount coordinates\nmatch the coordinates recorded for the cached image</li><li>If they match exactly, the cached image can be used\nwithout pulling from the registry</li><li>If they differ,  performs a fresh pull\nusing credentials for the new ServiceAccount</li></ul></li><li><p>With image pull credential verification enabled:</p><ul><li>Authorization is enforced using the recorded ServiceAccount coordinates,\nensuring pods only use images pulled by a ServiceAccount\nthey are authorized to use</li><li>Administrators can revoke access by deleting and recreating a ServiceAccount;\nthe UID changes and previously recorded authorization no longer matches</li></ul></li></ul><p>The beta release builds on service account node audience restriction\n(beta since v1.33) to ensure  can only request tokens for authorized audiences.\nAdministrators configure allowed audiences using RBAC to enable kubelet to request service account tokens for image pulls:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><h2>Getting started with beta</h2><ol><li><strong>Kubernetes v1.34 or later</strong></li><li>:\n<code>KubeletServiceAccountTokenForCredentialProviders=true</code> (beta, enabled by default)</li><li><strong>Credential provider support</strong>:\nUpdate your credential provider to handle ServiceAccount tokens</li></ol><p>If you're already using the alpha version,\nthe migration to beta requires minimal changes:</p><ol><li>:\nUpdate your credential provider configuration to include the required  field</li><li>:\nChoose between  and  cache types based on your provider's behavior</li><li><strong>Test audience restrictions</strong>:\nEnsure your RBAC configuration, or other cluster authorization rules, will properly restrict token audiences</li></ol><p>Here's a complete example\nfor setting up a credential provider with service account tokens\n(this example assumes your cluster uses RBAC authorization):</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>For Kubernetes v1.35, we - Kubernetes SIG Auth - expect the feature to stay in beta,\nand we will continue to solicit feedback.</p><p>You can also follow along on the\n<a href=\"https://kep.k8s.io/4412\">KEP-4412</a>\nto track progress across the coming Kubernetes releases.</p><p>In this blog post,\nI have covered the beta graduation of ServiceAccount token integration\nfor Kubelet Credential Providers in Kubernetes v1.34.\nI discussed the key improvements,\nincluding the required  field\nand enhanced integration with Ensure Secret Pull Images.</p><p>We have been receiving positive feedback from the community during the alpha phase\nand would love to hear more as we stabilize this feature for GA.\nIn particular, we would like feedback from credential provider implementors\nas they integrate with the new beta API and caching mechanisms.\nPlease reach out to us on the <a href=\"https://kubernetes.slack.com/archives/C04UMAUC4UA\">#sig-auth-authenticators-dev</a> channel on Kubernetes Slack.</p><p>If you are interested in getting involved in the development of this feature,\nshare feedback, or participate in any other ongoing SIG Auth projects,\nplease reach out on the <a href=\"https://kubernetes.slack.com/archives/C0EN96KUY\">#sig-auth</a> channel on Kubernetes Slack.</p><p>You are also welcome to join the bi-weekly <a href=\"https://github.com/kubernetes/community/blob/master/sig-auth/README.md#meetings\">SIG Auth meetings</a>,\nheld every other Wednesday.</p>","contentLength":6056,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev","k8s"]}