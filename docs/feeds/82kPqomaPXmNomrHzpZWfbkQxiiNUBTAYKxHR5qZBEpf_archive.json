{"id":"82kPqomaPXmNomrHzpZWfbkQxiiNUBTAYKxHR5qZBEpf","title":"Hacker News: Show HN","displayTitle":"HN Show","url":"https://hnrss.org/show?points=60","feedLink":"https://news.ycombinator.com/shownew","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":19,"items":[{"title":"Show HN: ChartDB Agent – Cursor for DB schema design","url":"https://app.chartdb.io/ai","date":1759325916,"author":"guyb3","guid":224,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45437594"},{"title":"Show HN: Glide, an extensible, keyboard-focused web browser","url":"https://blog.craigie.dev/introducing-glide/","date":1759261388,"author":"probablyrobert","guid":223,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45430294"},{"title":"Show HN: Sculptor – A UI for Claude Code","url":"https://imbue.com/sculptor/","date":1759250116,"author":"thejash","guid":222,"unread":true,"content":"<p>Dale used Sculptor to build <a href=\"https://lingolog.app\" node=\"[object Object]\" target=\"_blank\" rel=\"noopener noreferrer\">a foreign-language journaling app</a>. While Sculptor handled the refactors, fixed build issues, and churned through background tasks, he spent his time painting the landing page. In his words:</p><p>“In a world where generative art is booming, I used Sculptor to write code so that I could go make art.”</p>","contentLength":325,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45427697"},{"title":"Show HN: Devbox – Containers for better dev environments","url":"https://devbox.ar0.eu/","date":1759199199,"author":"TheRealBadDev","guid":221,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45421302"},{"title":"Show HN: Every single torrent is on this website","url":"https://infohash.lol/","date":1759162478,"author":"tdjsnelling","guid":220,"unread":true,"content":"<p><a href=\"https://en.wikipedia.org/wiki/BitTorrent\" target=\"_blank\">BitTorrent</a>is a communication protocol for peer-to-peer file sharing, which enables users to distribute data and files over the internet in a decentralized manner.</p><p>Every available torrent has a unique 40-character hexadecimal “infohash”. This website enumerates every possible infohash (of which there around 10) and displays them on pages of32 at a time, for a total ofpages.</p><p>BitTorrent clients can use a distributed hash table (DHT) to advertise themselves as a potential peer for a given infohash. When you load a page of infohashes, a DHT query is made for each of them to look for any advertising peers. If peers are found, another request is made to each to ask them for more metadata about the infohash, such as the name of the torrent and the files it contains.</p><p>The chance of randomly finding an active infohash is very small, but not zero...</p><p><em>* More accurately, every single torrent available to the DHT is on this website; clients can choose not to advertise themselves as peers in this way, and solely use tracker servers instead. This is often the case for ‘private’ torrents/trackers.</em></p><h2>Why do many torrents show a single peer, but never metadata?</h2><p>There is no validation that an infohash corresponds to a real torrent—any client can announce anything. Many crawlers and indexers continuously pick random or sequential infohashes and announce themselves so they can later detect other announcers, and malicious clients or poorly written bots can spam the network with anything they like.</p><p>This is further confirmed by the observation that swathes of sequential infohashes all share the same single peer. Who is the mysterious ..? 5 points to the person who works out who it is flooding the DHT!</p><p>It is also possible that a legitimate peer does not support the protocol extension required to exchange metadata.</p><p>Why not check out my other site,<a href=\"https://libraryofbabel.app\" target=\"_blank\">Library of Babel</a>, which contains every single book!</p>","contentLength":1900,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45415539"},{"title":"Show HN: Traceroute Visualizer","url":"https://kriztalz.sh/traceroute-visualizer/","date":1759134696,"author":"PranaFlux","guid":219,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45411514"},{"title":"Show HN: I built an MCP server using Cloudflare's code mode pattern","url":"https://github.com/jx-codes/codemode-mcp","date":1759076631,"author":"jmcodes","guid":218,"unread":true,"content":"<p>Read this article by Cloudflare this morning <a href=\"https://blog.cloudflare.com/code-mode/\" rel=\"nofollow\">https://blog.cloudflare.com/code-mode/</a> the main argument being that LLMs are much better at writing typescript code than tool calls because they've seen typescript code many more times.</p><p>Deno provides a great sandbox environment for Typescript code execution because of its permissions system which made it easy to spin up code that only has access to fetch and network calls.</p><p>Stick an MCP proxy on top of that and you've got \"CodeMode\" (code intermixed with MCP tool calls) for more advanced workflow orchestration.</p><p>There's a lot of things that can be improved here. Like a virtual file system for the agent to actually build up its solution instead of being forced to one shot the solution but the bones are there.</p>","contentLength":757,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45405584"},{"title":"Show HN: Toolbrew – Free little tools without signups or ads","url":"https://toolbrew.co/","date":1759070446,"author":"andreisergo","guid":217,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45404667"},{"title":"Show HN: Swapple, a little daily puzzle on linear reversible circuit synthesis","url":"https://swapple.fuglede.dk/","date":1759063323,"author":"fuglede_","guid":216,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45403912"},{"title":"Show HN: Curated gamedev specific search engine","url":"https://gamedevtorch.com/","date":1759055783,"author":"Voycawojka","guid":215,"unread":true,"content":"<img src=\"https://gamedevtorch.com/hello.0.svg\" alt=\"Hello!\"><p>GameDev Torch is a small gamedev specific search engine.</p><p>Search gamedev related articles, game engines, frameworks, blog posts and more from a  set of websites. Use it to complement your general purpose search engines to easily find niche resources.</p>","contentLength":248,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45403288"},{"title":"Show HN: The Unite real time operating system","url":"https://jacquesmattheij.com/unite-operating-system/","date":1759013422,"author":"jacquesm","guid":214,"unread":true,"content":"<p>tldr: A small i386 32-bit protected mode multi-tasking operating system modeled after QNX</p><p>Unite is an operating system in which  is a process, including the things that you normally would expect to be part of the kernel. The hard disk driver is a user process, so is the file system running on top of it. The namespace manager is a user process. The whole thing (in theory, see below) supports network transparency from the ground up, you can use resources of other nodes in the network just as easily as you can use local resources, just prefix them with the node ID. In the late 80’s, early 90’s I had a lot of time on my hands. While living in the Netherlands I’d run into the QNX operating system that was sold locally through a distributor. The distributors brother had need of a 386 version of that OS but Quantum Software, the producers of QNX didn’t want to release a 386 version. So I decided to write my own. Luck had it that I ended up in Poland and that the lack of work there meant I could spend a lot of time on this (life was super cheap there back then compared to my savings). In the space of about a year I wrote a proof-of-concept kernel using DJGPP and a very kludgy development system that required me resetting the system after every failure. And there were lots of failures. Thousands of them, until, finally, one day I had a very rudimentary kernel and an ‘idle’ appliation running on top of it.</p><p>The next couple of years, until February 1994 (right after my first child was born and I decided I should probably get serious about earning money) I steadily improved on the original until it had a full complement of tools, was self hosting and came with a window manager and some graphics demos.</p><p>When Linux was still very young, in 1992, there was a now infamous dispute between Andrew Tanenbaum, of MINIX fame and Linux Torvalds. The stakes were high: Tanenbaum thought Linus was wasting his time and talent building yet another macro kernel, he argued that micro kernels - even with a speed disadvantage - still have an edge in reliability and in speed of development. I agreed with Tanenbaum, but did not agree that MINIX was the way to go, I’d already seen QNX, and worked on my own variation on that theme and thought it was lightyears ahead of MINIX.</p><p>For the longest time this project sat on my hard drive in a state in which it could not run. The hardware that it had originally been developed on had died and I had never seen fit to spend more time on it to keep it bootable. Until the start of the fall of 2025, a good 30 years later, when I talked about it with my colleague I had not thought about putting any effort into a revival. In the meantime, a lot has happened. 32 bit systems are now already past, we’re on 64 bits now and 32 bit systems are usually doing only embedded stuff. We also have virtual machines, a luxury that my 30 year prior self would have happily traded a limb for, this makes development of such low level code a lot simpler than having to dive under the table every three minutes to hit the reset button. At some point this became such a routine that I hooked up a sustain pedal footswitch so I didn’t have to dive under the desk all the time.</p><p>So with modern tooling and the arena no longer vying for ‘the next best desktop solution’ I figured I should try to see if there is any life in it. Micro Kernels are fun to hack on: everything except for the core message passing task and scheduler is a user mode program and you can change it as easily as you can change any other program. That makes them unique and I think that this kind of hacking is now, especially with the more powerful embedded platforms within reach of just about anybody. The fact that it is a real time OS makes it much easier to work on hardware that requires guaranteed response time from the OS, there are 16 different priority levels and they offer very fine grained control over which tasks can be interrupted by which others.</p><h2>Reviving an OS that hasn’t run in 30 years</h2><p>This was a bit of a challenge. It took about two weeks, there were a couple of lucky breaks. The first was that I had not really done any cleaning of the repository where all this code was stored, so I had quite a few binaries that could run if I had a working OS. The second was that there was an image of a boot floppy. Between those two I managed to get the system booted under VirtualBox using a RAM disk. Some days later I had a working LBA capable hard drive, which I then populated with the contents of the ramdisk, and from there it was relatively quick work to recover the rest of the system.</p><p>The part that still eludes me is the bootfs.com program, this is the filesystem aware portion of the bootloader, that is loaded by the first stage on the boot floppy. There is some magic in there that for some reason does not play nice with the recovered version of TurboC, there is a chance I’m simply doing something wrong but I have not been able to successfully recompile that program and to get it to work so for now the system still boots from that original floppy image. But that’s fine, it’s not real hardware anyway and I’m sure if you really want to you can make it work again, all the pieces are there, I’ve added a VM disk image that should allow you to work on bootfs as well using freedos and some old binaries. Bootfs.com is a 16 bit real mode tiny memory model file that shuttles back-and-forth between real and protected mode to load all of the operating system components. It could boot from the hard drive as well (there is a ‘boot’ program to help you install the bootloader on an image) and like that you could do away with the floppy drive.</p><p>Well, it looks like any old boring text mode operating system. There is the usual complement of utilities, a C compiler (and a C++ compiler), both are ancient but they work. There is the source tree in /usr/kernel.src and /usr/src as well as the usual unix like locations for binaries and such. There is a shell. There is some networking support but - again - I have not been able to resurrect this, and I can’t get the emulated COM ports to work either, which would have been nice as a way to move data in and out (for instance, using SLIP).</p><p>Install QEMU. Download the distro (see below). Unzip the distro file, and cd to unite/os, after that run ./unite.sh and you should see a virtual machine boot up in text mode. After it has booted and you’ve clicked in the VM windows to give it keyboard focus hit alt-f2 to move to another console (one where you can type commands) and type ‘cd 3:/’ to move to the hard drive. If you’re used to some variety of Unix you will feel mostly at home but note that ‘cli’ (command line interpreter) is not a regular shell. Interesting bits to look at are in 1:/boot/config.0 and of course the directory tree of drive 3:/ (the simulated hard disk). The file system is a very much stripped down version of the MINIX file system as it was at the time, it was meant to be replaced but I never got around to it. If you type ‘tsk’ you can see which tasks are currently running and ‘sac’ gives you a rudimentary system activity monitor. If you’ve used QNX at all in the past you will feel right at home.</p><p>Unite does not have the concept of a user, it is very much a single user OS but that single user can have multiple sessions. There is also a graphics mode, you can activate it by changing the ‘mode’ line in 1:/config/config.0 to ‘mode 16’ but I’d advise against that until you have the COM ports working and are able to type commands through there so you can see what you’re doing. If you are  adventurous: make a backup of the fda.img file; change that mode line and reboot. You’ll end up in a completely blind graphics mode. You should then type the following (all blind so you won’t know if you did it right or not until it works): ‘cd 3:/’ ; ‘cd bin/gp’ ; ‘ontty /dev/console.4 gp’ ; ‘ontty /dev/console.4 qwm’ ; ‘ontty /dev/console.4 qwmdesk’ (now the screen should change) ; ‘ontty /dev/console.4 qwmcalc’ (now you should see a small calculator, it would work if you had mouse/keyboard support but you don’t) ; ‘ontty /dev/console.4 qwmline’ (which should show a bouncing line demo).</p><p>Now you have a problem: if you reboot the system it will go right back to that graphics mode. So now you want to restore that fda.img backup you made above.</p><p>The operating system is distributed as a torrent:</p><p>magnet:?xt=urn:btih:bb01f5651944948b1b705ae4efa5ab5578bdee00&amp;dn=unite.zip</p><p>The torrent contains a single zip file that you unpack, then you follow the instructions above.</p><ul><li><p>I have only tested this under Linux using VirtualBox and Qemu, I have not ran it under a Windows VM or on real hardware and you may run into issues if you do.</p></li><li><p>there is no networking, this is probably the first thing that really needs doing</p></li><li><p>the COM ports don’t work yet (this seems to be an emulation issue, I have yet to see a single byte in or out)</p></li><li><p>the mouse driver (mp) does not work (it relies on a mouse plugged into a COM port, see above)</p></li><li><p>the version of vi that is in /bin seems to add random cruft to files, I have not been able to figure out yet what the reason for that is.</p></li><li><p>there is an alternative editor ‘e’ that does work, and that I wrote back in the stone age</p></li><li><p>this is not/was not an effort at making something that is ‘secure’, if you plan on using this be very much aware of that and that you are most likely going to open yourself up to being compromised within seconds if you hook this up to the big bad internet. I was already very happy that I got as far as I did. But the Micro Kernel concept lends itself well to modification and you can start hacking on the kernel pretty much immediately, it is that simple.</p></li><li><p>it is i386 protected mode only right now if you want another CPU or 64 bit then you have a lot of (fun!) work ahead of you.</p></li><li><p>I have plenty to do and will not be available to manage this project or to even administer it, the source code is my full and only contribution, from here on in if you want to do something with it you are essentially on your own (or with your friends!), I have a lot of other stuff on my plate that takes precedence, so apologies for that but I still hope you find this useful.</p></li></ul><p>There are a lot of pieces that have been cobbled together from various other distributions, these were all made available at the time so in theory they should be fine to use but I have not verified whether any of those licenses have since been retracted or modified. Whichever party contributed the code still has the rights and this release is under the exact same license as under which the code was originally released in the early 90’s. The remaining code, the part of the code that I lay claim to (the core OS, the editor and the graphics library) I herewith place in the public domain, you can do with it whatever you want, as long as you credit the project and include a link to this page so others can start off from the same point. If you release an interesting derivative let me know and I’ll add a link to this page.</p><ul><li>Henri Groenweg wrote the memory manager</li><li>Marcel Wouters wrote the console and display driver</li><li>DJGPP, by DJ DeLorie was the key to being able to start this at all</li><li>QNX served as a very useful model and inspiration</li><li>MINIX, provided in source code made it possible to have a file system; so thank you Andrew Tanenbaum, this made a massive difference</li></ul>","contentLength":11462,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45400006"},{"title":"Show HN: I spent 4 months building Duolingo but for your life","url":"https://three-cells.com/","date":1758978634,"author":"maghfoor","guid":213,"unread":true,"content":"<p>Zero fluff. Just what matters.</p>","contentLength":30,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45395428"},{"title":"Show HN: Dreamtap – Make your AI more creative","url":"https://dreamtap.xyz/","date":1758899491,"author":"neural_thing","guid":212,"unread":true,"content":"<article><p>When you ask AI to write stories, you've probably noticed they are frequently incredibly similar. Claude, for example, likes lighthouses and cartographers.</p><p>This is  – the AI defaulting to the safest, most average patterns in its training data. Every story becomes a slight variation of the same template.</p></article><article><p>Dreamtap injects <strong>randomized sources of inspiration</strong> before your AI starts generating. Instead of letting the model slide into its default patterns, it inspires the model with some concepts unconnected to your prompt. Claude decides by itself when it needs more inspiration and uses Dreamtap. ChatGPT is a bit worse at this, and you'll need to use the tool manually.</p></article><article><h2>The Difference in Practice</h2><p>Below are stories written by Claude with the same prompt: <em>\"Write an inspired short story\"</em></p></article>","contentLength":784,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45387421"},{"title":"Show HN: A little notebook for learning linear algebra with Python","url":"https://little-book-of.github.io/linear-algebra/books/en-US/lab.html","date":1758879973,"author":"tamnd","guid":211,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45384617"},{"title":"Show HN: Vibe Linking","url":"https://vb.lk/","date":1758732011,"author":"michaelstewart","guid":210,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45362813"},{"title":"Show HN: Dayflow – A git log for your day","url":"https://github.com/JerryZLiu/Dayflow","date":1758725637,"author":"jerryliu12","guid":209,"unread":true,"content":"<p>Hi HN! I've been building Dayflow, a macOS app that automatically tracks what you're actually working on (not just which apps you have open).</p><p>- It creates a semantic timeline of your day;</p><p>- It does it by understanding the content on your screen (with local or cloud VLMs);</p><p>- This allows you to see exactly where your time went without any manual logging.</p><p>Traditional time trackers tell you \"3 hours in Chrome\" which is not very helpful. Dayflow actually understands if you're reading documentation, debugging code, or scrolling HN. Instead of \"Chrome: 3 hours\", you get \"Reviewed PR comments: 45min\", \"Read HN thread about Rust: 20min\", \"Debugged auth flow: 1.5hr\".</p><p>I was an early Rewind user but rarely used the retrieval feature. I built Dayflow because I saw other interesting uses for screen data. I find that it helps me stay on track while working - I check it every few hours and make sure I’m spending my time the way I intended - if I’m not, I try to course correct.</p><p>Here’s what you need to know about privacy:</p><p>- Run 100% locally using qwen2.5-vl-3b (~4GB model)</p><p>- No cloud uploads, no account</p><p>- Optional: BYO Gemini API key for better quality (stored in Keychain, with free-tier workaround to prevent training on your data)</p><p>The tech stack is pretty simple, SwiftUI with a local sqlite DB. Uses native macOS apis for efficient screen captures. Since most people who run LLMs locally already have their tool of choice (Ollama, LLMStudio, etc.), I decided to not embed an LLM into Dayflow.</p><p>By far the biggest challenge was adapting from SOTA vision models like Gemini 2.5 Pro to small, local models. My constraints were that it had to take up &lt;4GB of ram and have vision capabilities. I had to do a lot of evals to figure out that Qwen2.5VL-3B was the best balance of size and quality, but there was still a sizable tradeoff in quality that I had to accept. I also got creative with sampling rates and prompt chunking to deal with the 100x smaller context window. Processing a 15 minute segment takes ~32 local LLM calls vs 2 Gemini calls!</p><p>Here’s what I’m working on next:</p><p>Distillation: Using Gemini's high-quality outputs as training data to teach a local model the patterns it needs, hopefully closing the quality gap.</p><p>Custom dashboards where you can track answers to any question like \"How long did I spend on HN?\" or \"Hours until my first deep work session of the day</p><p>I'd love to hear your thoughts, especially if you've struggled with productivity tracking or have ideas for what you'd want from a tool like this.</p>","contentLength":2520,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45361268"},{"title":"Show HN: Python Audio Transcription: Convert Speech to Text Locally","url":"https://www.pavlinbg.com/posts/python-speech-to-text-guide","date":1758565136,"author":"Pavlinbg","guid":208,"unread":true,"content":"<p>Last week, I faced a dilemma that many researchers, journalists, and content creators know all too well: I had hours of recordings that needed to be transcribed. I had serious privacy concerns about uploading sensitive content to commercial transcription services and their third-party servers.</p><p>Instead of risking it, I built a Python-based transcription system using OpenAI’s Whisper model. The result? All my audio files were transcribed in under 10 minutes with 96% accuracy—completely free and processed locally on my laptop.</p><p>In this post, I will show you how you can build a simple script for processing any audio data without recurring costs or privacy compromises.</p><h2>Essential Setup Requirements</h2><h3>1. FFmpeg Installation (Critical First Step)</h3><p>FFmpeg handles audio processing and is required for all transcription methods. <strong>This is the #1 cause of setup failures.</strong></p><div role=\"note\" aria-labelledby=\"note-m2elpd0ou-title\"><div><div><div>Install FFmpeg FIRST before any Python packages. Most transcription errors stem from missing or misconfigured FFmpeg. Don't skip this step—it will save you hours of debugging later.</div></div></div></div><ol><li>Add  to your PATH environment variable</li></ol><pre tabindex=\"0\" data-language=\"bash\"><code></code></pre><pre tabindex=\"0\" data-language=\"bash\"><code></code></pre><p>You should see version information. If you get “command not found,” FFmpeg isn’t properly installed.</p><h3>2. Python Environment Setup</h3><div role=\"note\" aria-labelledby=\"note-d8hrlq5ik-title\"><div><div><h4> Virtual Environment Benefits </h4><div>Using a virtual environment prevents package conflicts, keeps your system Python clean, and makes your setup reproducible across different machines. It's a best practice that will save you from dependency hell.</div></div></div></div><pre tabindex=\"0\" data-language=\"bash\"><code></code></pre><p>Whisper is OpenAI’s state-of-the-art speech recognition model, trained on 680,000 hours of multilingual audio. It’s specifically designed for robust, real-world audio transcription and handles various accents, background noise, and audio quality issues remarkably well.</p><h3>Choosing the Right Whisper Model</h3><div role=\"note\" aria-labelledby=\"note-03c78d89t-title\"><div><div><div>Start with 'base' model for most use cases. It offers the best balance of speed, accuracy, and resource usage for typical projects. Only upgrade to 'small' or 'medium' if you specifically need higher accuracy and have the computational resources.</div></div></div></div><table><thead><tr></tr></thead><tbody><tr><td>Quick testing, real-time applications</td></tr><tr><td><strong>General use (recommended)</strong></td></tr><tr><td>High-quality transcription needs</td></tr><tr><td>Professional work, critical accuracy</td></tr><tr><td>Maximum accuracy, research purposes</td></tr></tbody></table><h3>Basic Whisper Implementation</h3><p>Here’s a clean, production-ready implementation:</p><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><div role=\"note\" aria-labelledby=\"note-b3p1giyj2-title\"><div><div><div>Whisper supports most common audio formats out of the box: WAV, MP3, MP4, M4A, FLAC, OGG, and more. No need to convert files beforehand—FFmpeg handles the conversion automatically in the background.</div></div></div></div><h3>Batch Processing Multiple Files</h3><p>For processing multiple audio files efficiently:</p><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><p>Generate subtitle files for videos:</p><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><h2>Method 2: Alternative with SpeechRecognition Library</h2><p>For scenarios requiring different recognition engines or more control over audio preprocessing:</p><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><div role=\"note\" aria-labelledby=\"note-gm5h6hez7-title\"><div><div><div>Google: High accuracy, requires internet connection and has usage limits. Sphinx: Completely offline, lower accuracy but no external dependencies. Choose Google for best results, Sphinx for complete privacy and offline use.</div></div></div></div><h3>Issue 1: FFmpeg Not Found</h3><p><code>[WinError 2] The system cannot find the file specified</code></p><ul><li>Verify FFmpeg installation: </li><li>Windows: Ensure FFmpeg is in your PATH environment variable</li><li>Restart your terminal/command prompt after PATH changes</li><li>Try reinstalling FFmpeg if the problem persists</li></ul><h3>Issue 2: Out of Memory Errors</h3><p> CUDA out of memory or system RAM exhausted</p><div role=\"note\" aria-labelledby=\"note-fq4gzk8i4-title\"><div><div><div>For files longer than 1 hour, use the 'tiny' or 'base' model. For files over 2 hours, consider chunking the audio or processing on a machine with more RAM. GPU acceleration helps with speed but requires more VRAM.</div></div></div></div><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><h3>Issue 3: Poor Accuracy on Noisy Audio</h3><p> Low accuracy on recordings with background noise or poor quality</p><div role=\"note\" aria-labelledby=\"note-p1xxbugr8-title\"><div><div><div>Best results come from: 16kHz+ sample rate, minimal background noise, clear speech, and audio levels between -12dB to -6dB. Record in quiet environments when possible. Even small improvements in audio quality dramatically improve transcription accuracy.</div></div></div></div><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><ol start=\"2\"><li><strong>Specify language for better accuracy:</strong></li></ol><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><ol start=\"3\"><li><strong>Use higher-quality model:</strong></li></ol><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><p>Based on testing with various audio types on a modern laptop:</p><p><strong>Whisper Model Performance (1-hour audio file):</strong></p><ul><li>: 1.9 minutes processing, 89% accuracy</li><li>: 3.8 minutes processing, 94% accuracy</li><li>: 10 minutes processing, 96% accuracy</li><li>: 30 minutes processing, 97% accuracy</li></ul><ul><li>: Use base model maximum for reasonable speeds</li><li>: Comfortable with small model</li><li>: Can handle medium/large models without issues</li><li>: 3-5x speed improvement (requires CUDA setup)</li></ul><div role=\"note\" aria-labelledby=\"note-vyccc5u7g-title\"><div><div><div>Start with 'base' model on CPU for the best balance of speed and accuracy. If accuracy is insufficient for your use case, upgrade to 'small'. Only use GPU acceleration if you're processing large volumes of audio regularly—the setup complexity isn't worth it for occasional use.</div></div></div></div><p>Create a simple command-line script for easy usage:</p><pre tabindex=\"0\" data-language=\"python\"><code></code></pre><pre tabindex=\"0\" data-language=\"bash\"><code></code></pre><p>Local audio transcription with Python and Whisper offers a compelling alternative to commercial services. With a one-time setup, you get unlimited transcription capabilities, complete privacy, and often superior accuracy compared to cloud-based solutions.</p><ul><li> after initial setup—no per-minute charges</li><li>—audio never leaves your machine</li><li>—94-98% depending on model choice and audio quality</li><li>—typically 4-16x real-time speed</li><li>—works without internet connection</li><li>—transcribe as much as you want</li></ul><p>Whether you’re a researcher transcribing interviews, a journalist working with sensitive sources, or a content creator processing podcasts, this local solution gives you the control and privacy that cloud services can’t match.</p><p>The setup might take 30 minutes, but you’ll save hours of time and potentially hundreds of dollars in transcription costs. Plus, you’ll have the peace of mind that comes with keeping your audio data completely under your control.</p>","contentLength":5613,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45337400"},{"title":"Show HN: Software Freelancers Contract Template","url":"https://sopimusgeneraattori.ohjelmistofriikit.fi/?lang=en","date":1758526543,"author":"baobabKoodaa","guid":207,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45330198"},{"title":"Show HN: Tips to stay safe from NPM supply chain attacks","url":"https://github.com/bodadotsh/npm-security-best-practices","date":1758489587,"author":"bodash","guid":206,"unread":true,"content":"<p>I'd love for you to check it out, and contribute your own insights and best practices to make this a comprehensive resource for the community.</p>","contentLength":142,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45326754"}],"tags":["dev","hn"]}